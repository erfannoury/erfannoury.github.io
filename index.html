
<!DOCTYPE html>
<html dir="rtl" lang="fa-IR">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width" />
    <meta http-equiv="last-modified" content="2017-11-18T16:29:23.0508385-05:00" />
    <meta name="keywords" content="" />
    <title>The Gradient</title>
    <link rel="stylesheet" type="text/css" href="/stylesheets/font-awesome/css/font-awesome.min.css" />
    <link rel="stylesheet" type="text/css" href="/stylesheets/style.css" />
    <script type="text/javascript"
        src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
    <!--<script type="text/javascript">    
        MathJax.Hub.Config({    
            "HTML-CSS": { scale:100}    
        });    
    </script>-->
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true
            }
        });
    </script>



   <link rel="canonical" href="http://blog.erfan.xyz/" />
   <script type="text/javascript">
      window.heap=window.heap||[],heap.load=function(t,e){window.heap.appid=t,window.heap.config=e;var a=document.createElement("script");a.type="text/javascript",a.async=!0,a.src=("https:"===document.location.protocol?"https:":"http:")+"//cdn.heapanalytics.com/js/heap-"+t+".js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(a,n);for(var o=function(t){return function(){heap.push([t].concat(Array.prototype.slice.call(arguments,0)))}},p=["clearEventProperties","identify","setEventProperties","track","unsetEventProperty"],c=0;c<p.length;c++)heap[p[c]]=o(p[c])};
      heap.load("2204913712");
    </script>

</head>
<body class="home blog">
    <div id="page" class="hfeed site">
        <header id="masthead" class="site-header" role="banner">
            <hgroup>
                <h1 class="site-title"><a href="/" title="The Gradient" rel="home">The Gradient</a>
                <p>
                    <small>
                        ماجراجویی‌های من به عنوان یه تازه‌کار
                    </small>
                </p>
                </h1>
            </hgroup>
            <nav role="navigation" class="site-navigation main-navigation">
                <h1 class="assistive-text">منو | Menu</h1>
                <div class="assistive-text skip-link"><a href="#content" title="Skip to content">ادامه به اصلِ مطلب | Skip to content</a></div>
                <div class="menu">
                    <ul>
                        <li><a href="/" class="home"><i class="fa fa-home fa-lg"></i></a></li>
                        <!-- <li><a href="/about">درباره‌ی من</a></li> -->
                        <li><a href="http://ce.sharif.edu/~noury">درباره‌ی من | About Me</a></li>
                        <li><a href="/category">موضوع‌بندی‌ها | Categories</a></li>
                        <li><a href="/archive">آرشیو | Archive</a></li>
                        <li><a href="/rss.xml"><i class="fa fa-rss-square fa-lg" style="color:orange"></i></a></li>
                        <li><a href="/feed.xml"><i class="fa fa-rss fa-lg" style="color:orange"></i></a></li>
                    </ul>
                </div>
            </nav>
        </header>
        <div id="main">
            <div id="primary" class="site-content">
                <div id="content" role="main">
                  

  <ul class="posts">
    <li class="post">
      <h1><a href="/2017/11/ai-for-society/">هوش مصنوعی برای جامعه</a></h1>
      <div class="meta">
        <p class="posted"><i class="fa fa-calendar"></i> 18 Nov 2017</p>
        <ul class="categories">
        <i class="fa fa-tag"></i>
          <li><a href="/category/Aritifical Intelligence" title="Aritifical Intelligence">Aritifical Intelligence</a></li>
          <li><a href="/category/Society" title="Society">Society</a></li>
        </ul>
      </div>
      
      <h1>به نام خدا</h1>

<p>فکر کنم دور از ذهن نیست اگر بقیه‌ی مطالب این وبلاگ رو خونده باشید بدونید که مهم‌ترین زمینه‌ای که روش تمرکز دارم در حال حاضر هوش مصنوعی هست. از زمانی که تورینگ مقاله‌ی «ادوات محاسبه‌گری و هوش»[۱]
رو منتشر کرد ۶۸ سال می‌گذره. تو این مدت زمان خیلی اتفاق‌ها افتاده و هوش مصنوعی خیلی سرد و گرم کشیده. ولی حالا زمانی هست که بیشتر از هر وقت دیگه‌ای آدم‌های کارپشته و تازه‌کارهایی مثل من وارد این حوزه شدن. شاید بشه گفت الان مهم‌ترین تکنولوژی حاضر بشر هست که داره به شکوفایی میرسه. احتمالاً برای همه هم واضح باشه که تو چهار پنج سال اخیر پیشرفتش قابل مقایسه با قبل نبوده. حالا کاملاً از دانشگاه‌ها خارج شده و توی جامعه دنبال میشه و به طور مستقیم به اکثر جوامع تاثیر می‌گذاره.</p>

<p>احتمالاً اگر دسترسی به اینترنت داشته باشید، در مورد این هم اطلاع دارید که کلی آدم دارن در مورد این صحبت می‌کنن که اگر بتونیم به هوش عمومی مصنوعی [۲] برسیم، به احتمال زیادی نسل بشر منقرض خواهد شد. در مقابل یه سری هم هستن که میگن اگر به هوش عمومی مصنوعی برسیم دیگه زندگی انسان‌ها تبدیل به بهشت خواهد شد. به هر دو دسته‌ای که زمان حال یا آینده‌ی نزدیک رو ول کردن و دارن در مورد آینده‌ی نامعلوم دست‌یابی به هوش عمومی مصنوعی صحبت می‌کنن، میگن تکینه‌گراها [۳]، کسایی که غالباً خیلی احساسی و تعصبی در مورد این مسائل صحبت می‌کنن. البته حرف‌هاشون خیلی بیهوده هم نیست، واقعاً این خطر به شکل جدی وجود داره. ولی معمولاً وسط این حرف‌های اغراق‌آمیز در مورد یک آینده‌ی نامعلوم و شاید نه چندان نزدیک، اهمیت زمان حال و آینده‌ی خیلی نزدیک خیلی گم میشه. اون قدری که به حرف‌های تکینه‌گراها گوش داده میشه و کار انجام میشه، کار در مورد اثرات هوش مصنوعی بر روی جوامع و انسان‌ها انجام نمیشه.</p>

<p>شاید آخرین تکنولوژی خیلی مخربی که بشر بهش دست یافته باشه تکنولوژی تولید سلاح‌های هسته‌ای باشه. معمولاً وقتی در مورد خطرات هوش عمومی مصنوعی صحبت میشه، حتماً حرف سلاح‌های هسته‌ای هم وسط میاد. ولی فکر می‌کنم تفاوت عمده‌ای بین این دو تکنولوژی وجود داره که زیاد بهش توجه نمیشه. اگر یک دولت، مثل دولت امریکا، با یه پروژه‌ی خیلی بزرگ مقیاس مثل پروژه‌ی منهتن تونست به این تکنولوژی دست پیدا بکنه و بعد از سال‌ها این تکنولوژی فقط دست «دولت»های معدودی هست، نشون میده که موانع ورود به این حوزه خیلی خیلی بزرگ هستن.
ولی، موانع ورود به حوزه‌ای مثل هوش مصنوعی اصلاً اونقدر بزرگ نیستن. درسته برای یه چند تا دانشجو خریدن کارت گرافیکی سخت باشه، ولی هم‌زمانی وجود اینترنت، وجود داده، وجود زیرساخت‌های محاسباتی، و حرکت ارزشمند open source و مشابه اون در به اشتراک گذاری تحقیقات، یک هم‌زمانی منحصربفرد هست.
فکر کنید به جای اینکه پروژه‌ی منهتن یک پروژه‌ی مخفی باشه، با چند نفر محدود که روش کار می‌کردن، این یه حرکت بین‌المللی باشه بین تعداد زیادی آدم و شرکت، که کلی امکانات در اختیار دارن و آزادانه همه‌ی نتایج و دستاوردها رو به اشتراک میذارن. مثلاً فرض کنید اپنهایمر به یه چیز جدید در مورد تکنولوژی هسته‌ای میرسه، بعد میشینه آخر هفته یه مقاله می‌نویسه، جمعه شب (یا به طور مشابه یک‌شنبه شب) مقاله رو به آرکایو [۴] سابمیت می‌کنه و دو روز بعد، صبح دانشمندان روسی یا آلمانی که از خواب بیدار میشن میرن مقاله‌ی اپنهایمر و دوستان رو دانلود می‌کنن و از آخرین دستاوردهاشون در مورد ساخت سلاح‌های هسته‌ای استفاده می‌کنن. تصور می‌کنید این شرایط رو؟ این شرایط برای هوش مصنوعی وجود داره. ولی اتفاقات کوتاه مدتی که توی هوش مصنوعی میوفته به اندازه‌ی یک سلاح هسته‌ای صدا نمی‌کنن. خیلی کوچک‌تر هستن. یک سلاح هسته‌ای تاثیر مخربی رو جمعیت نسبتاً کمی (نسبت به جمعیت کل جهان) میذاره. ولی یک محصولی که هوش مصنوعی داشته باشه می‌تونه تاثیر خیلی کمی روی جمعیت خیلی بزرگی بذاره. تاثیرش هم معمولاً روی هر فرد به اندازه‌ای کمه که هیچ کسی رو از اتفاقی که داره میوفته خبردار نمی‌کنه.
مشکل اصلی هوش مصنوعی دقیقاً چیزی هست که باعث شده به این وضعیت پیشرفته‌ی فعلیش برسه، راحتی پیشبردش.</p>

<p>اول این ویدیو رو ببینید:</p>

<div style="text-align:center;">
<iframe style="display:block" width="1280" height="720" src="https://www.youtube-nocookie.com/embed/xhp47v5OBXQ?rel=0" frameborder="0" allowfullscreen></iframe>
</div>

<p>شاید اول فکرتون به این سمت بره که اگر دولت‌ها به این تکنولوژی‌ها دسترسی داشته باشن (که قطعاً دارن) چه کارهایی میشه باهاش کرد که اهداف بیشترشون در تضاد حقوق شهروندی می‌تونه باشه. ولی مسئله‌ی اصلی اینه که دسترسی به تکنولوژی اونقدر راحت هست که نه تنها دولت‌ها، بلکه هر کس دیگه‌ای می‌تونه بهش دسترسی داشته باشه و بر اساس نیازهاش تغییرش بده.</p>

<p>حال این ویدیو رو ببینید:</p>

<div>
<iframe width="1280" height="720" src="https://www.youtube-nocookie.com/embed/9CO6M2HsoIA?rel=0" frameborder="0" allowfullscreen></iframe>
</div>

<p>این ویدیو ساختگی هست، برای کمپین ایجاد قوانین محدودکننده برای سلاح‌های خودمختار [۵]. این ویدیو خیلی باعث ترس و نگرانی من شد. چیزی که توی این ویدیو نشون میدن تکنولوژی عجیب یا دور از دسترسی نیست. شاید یک تیم چند نفره‌ای که برنامه‌نویسی بلد هستن بتونن در مدت چند ماه حرکت هوشمندانه‌ی این پهپاد رو درست بکنن. درست کردن بقیه‌ی قسمت‌هاش هم خیلی زمان نمی‌بره.درسته تخمین‌های من اشتباه هستن، ولی رسیدن به این تکنولوژی نیازی به زمان و هزینه و تخصص (در عمل به اندازه‌ی) بینهایت نداره. با منابع محدودتری هم میشه به این تکنولوژی دست یافت و این خیلی ترسناکه.)
شاید کشورهایی که در اون‌ها جایگاه و منزلت قانون بیشتره، مثل امریکا یا کشورهای اتحادیه‌ی اروپا واقعاً بتونن به قوانین محدود کننده دست پیدا بکنن، ولی نگرانی بزرگ‌تر اینجا شروع میشه. کشورهایی که به اندازه‌ی کافی در چارچوب قوانین نیستن و یا تمامیت‌خواه و سرکوب‌گر هستن، به راحتی می‌تونن از این تکنولوژی‌های برای مقاصد نادرست استفاده بکنن. علاوه بر اون کشورهای تابع قوانین هم خیلی راحت می‌تونن این تکنولوژی‌هاشون رو بر روی ملل دولت‌های ضعیف‌تر امتحان بکنن. بخاطر همینه که پیشرفت تکنولوژی از خیلی جهات خیلی بیشتر باعث ضرر مردمان کشورهای ضعیف از نظر سیاسی و دسترسی به تکنولوژی میشه. این مردمان (ما مردمان) هم از طرف دولت‌های خودشون (خودمون) با ابزار تکنولوژی هوش مصنوعی می‌تونن (می‌تونیم) مورد سرکوب قرار بگیرن (بگیریم) و هم از طرف دولت‌های صادرکننده‌ی دموکراسی. واقعاً در این زمان خیلی سخته شهروند کشوری بود که در اون کشور به اندازه‌ی کافی و لازم به قوانین احترام گذاشته نمیشه.</p>

<p>ولی خب به هر حال نمیشه جلوی پیشرفت تکنولوژی رو گرفت. اتفاقاً جلوی پیشرفتش رو هم گرفتن اشتباهه. در مورد برخورد با هوش مصنوعی چند تا راهکار اصلی وجود داره. بعضی‌ها عقیده دارن که همه‌ی نتایج و دستاوردها باید آزادانه و به سرعت با همه به اشتراک گذاشته بشه تا برتری استراتژیک زیادی بین طرف‌های مختلف وجود نداشته باشه. شاید بشه گفت تا حدودی وضعیت فعلی اهالی دانشگاه و محققان دانشگاهی که در صنعت هستن اینطوری باشه. نظر گروه دیگه‌ای اینه که دستاوردها باید با تامل بیشتری به اشتراک گذاشته بشن. تا وقتی که در مورد درستی و بی‌خطری دستاوردی مطمئن نشدیم نباید اون دستاورد رو با بقیه به اشتراک بذاریم. دسته‌ی آخر هم نظرشون اینه که کلاً باید همه چیز پشت درهای بسته باشه تا همیشه برتری استراتژیک دست ما (که برگزیده‌ترین افراد برای داشتن این اسرار هستیم و صلاح همه‌ی بشر رو بیشتر می‌دونیم) باشه و دست «انسان‌های بد» نیوفته. البته بدیهیه که این رویکرد خیلی شکننده است.</p>

<p>من به اندازه‌ی کافی در مورد این رویکردها فکر نکردم، ولی نظر فعلیم اینه که اشتراک‌گذاری بدون وقفه و آزادانه شاید بهترین روش فعلی باشه. ولی قطعاً این روش پایداری نیست و بهترین گزینه نیست. این روش تضمین نمی‌کنه که همه‌ی طرفین آزادانه دارن همه‌ی نتایج و دستاوردهاشون رو به اشتراک می‌ذارن و اتفاقاً کسایی که با قوانین این بازی، بازی نمی‌کنن شاید بشه گفت که سود بیشتری می‌برن.</p>

<p>از اون طرف به کارگیری روزمره‌ی تکنولوژی‌های مبتنی بر هوش مصنوعی در همه‌ی زمینه‌های زندگی حتماً اثرات منفی مختلفی داره ولی نمیشه جلوی این رو گرفت. به نظر شما چطوری میشه اثرگذاری این تکنولوژی رو مثبت‌تر کرد؟ واقعاً آیا راه‌حلی وجود داره؟</p>

<p>اگر خیلی مثل گذشته تنبلی بر من غلبه نکنه، در آینده بیشتر در مورد ایمنی هوش مصنوعی [۶] خواهم نوشت.</p>

<p>[1] Turing, Alan M. "Computing machinery and intelligence." Mind 59.236 (1950): 433-460.</p>

<p>[2] Artificial General Intelligence</p>

<p>[3] Singularitarians</p>

<p>[4] arxiv.org/</p>

<p>[5] Autonomous Weapons</p>

<p>[6] AI Safety</p>

      <!--<p><a href="/2017/11/ai-for-society/">ادامه‌ی مطلب</a></p>-->
    </li>
    <hr/>
    <li class="post">
      <h1><a href="/2017/08/arxiv-sat-20170812/">شنبه‌های آرکایو (دوشنبه ۱۶ مرداد - شنبه ۲۱ مرداد)</a></h1>
      <div class="meta">
        <p class="posted"><i class="fa fa-calendar"></i> 12 Aug 2017</p>
        <ul class="categories">
        <i class="fa fa-tag"></i>
          <li><a href="/category/Deep Learning" title="Deep Learning">Deep Learning</a></li>
          <li><a href="/category/Research" title="Research">Research</a></li>
        </ul>
      </div>
      
      <h1>به نام خدا</h1>

<p>در مورد شنبه‌های آرکایو
<a href="https://github.com/n1analytics/python-paillier/blob/master/phe/paillier.py#L746-L748">قبلاً</a>
نوشتم. این بار تصمیم گرفتم که برای هر هفته پستی بنویسم و مقالات جالبی رو که پیدا کردم معرفی کنم.
فعلاً این هفته به صورت آزمایشی این کار رو انجام میدم تا بعد تصمیم بگیرم که آیا ادامه خواهم داد یا نه.</p>

<p>این هفته ۴۷۲ عنوان جدید تو قسمت‌های منتخب آرکایو بارگزاری شده که البته این، عدد، تعداد مقالات یکتا نیست.
تعداد مقالات یکتا شاید نصف این عدد باشه.
دلیلش اینه که بعضی از مقالات ممکنه که در بیش از یک موضوع دسته‌بندی شده باشن.
این بار cs.CV (طبق معمول) بیشترین مقاله‌ی جدید رو با ۱۴۲ عنوان جدید داشت.</p>

<p>قسمت‌هایی که من دنبال می‌کنم این قسمت‌ها هستن:</p>

<ul>
<li>cs.{AI, CG, CL, CV, IR, LG, NE, RO}</li>
<li>stat.ML</li>
</ul>

<h2>مقالات منتخب هفته‌ی گذشته</h2>

<p><strong>"Regularizing and Optimizing LSTM Language Models"</strong> - <a href="https://arxiv.org/abs/1708.02182">1708.02182</a></p>

<p>Stephen Merity, Nitish Shirish Keskar, Richard Socher</p>

<p>Salesforce Research</p>

<p>در این مقاله مسئله‌ی آموزش مدل‌های زبانی سطح کلمه (word-level) مورد توجه قرار گرفته و روش‌های مختلف بهینه‌سازی و تنظیم (regularization) مدل‌های مبتنی بر LSTM بررسی شدن.</p>

<p>از طریق این روش‌های بهبود یافته‌ی آموزش مدل‌های زبانی مبتنی بر LSTM، در این مقاله تونستن به بهترین نتیجه روی دو دیتاست Penn Tree Bank و WikiText-2 دست پیدا کنن.</p>

<p>یکی از این روش‌ها، استفاده از DropConnect با ماسک ثابت در راستای زمان، برای اتصالات پنهان-به-پنهان در فرمول‌بندی LSTM هست.
تفاوت DropConnect با Dropout در این هست که در Dropout ماسک تصادفی بر روی خروجی یک لایه اعمال میشه تا لایه‌ی بعد به عنوان ورودی، نسخه‌ای مخدوش‌شده از خروجی لایه‌ی قبل رو بگیره.
در مقابل در DropConnect این ماسک تصادفی بر روی وزن‌های یک لایه‌ی fully-connected اعمال میشه.</p>

<p>برای بقیه‌ی اتصالات در این کار از Dropout معمولی استفاده شده، ولی ماسک تصادفی یک بار نمونه‌گیری شده و در طول دنباله از این ماسک استفاده شده، یعنی در واقع Variational Dropout.
کار دیگه‌ای هم که در این مقاله انجام شده استفاده از Dropout بر روی ماتریس Embedding هست، به این شکل که در هر بار نمونه‌گیری از ماسک تصادفی ممکنه تعدادی از کلمات حذف بشن.
طبق معمول یه سری کارهای قبلی در زمینه‌ی یادگیری مدل زبانی و ترجمه‌ی ماشینی، در این کار وزن‌های ماتریس Embedding و لایه‌ی خروجی (یا لایه‌ی softmax) مشترک هستن.
این کار هم باعث میشه که تعداد پارامترهای مدل کم بشه و هم اینکه یک شهود نظری پشت این کار هست <a href="https://arxiv.org/abs/1611.01462">1</a>.</p>

<p>یک regularization جالب دیگه‌ای که انجام دادن
Activation Regularization و
Temporal Activation Regularization هست که تقریباً جدید هستن و تو کارهای زیادی قبلاً ندیدم.
توی Activation Regularization هدف اینه که خروجی میانی LSTM مقادیر کوچکی بگیرن،‌ یعنی</p>

<p>$$ \alpha L _ 2 (m \odot h _ t) $$.
در مقابل در Temporal Activation Regularization
هدف اینه که خروجی‌های میانی LSTM در طول زمان خیلی متغیر نباشن، یعنی</p>

<p>$$ \beta L _ 2 (h _ t - h _ {t+1}) $$</p>

<p>در کل به نظر میاد که مقاله‌ی خوبی باشه و بشه به نتایج‌شون اعتماد کرد، هر چند تا جایی که می‌دونم کد مقاله رو منتشر نکردن.
اگر می‌خوایید از LSTM برای پردازش دنباله استفاده کنید، بخصوص برای مدل‌های زمانی، خوندن این مقاله فکر می‌کنم مفید می‌تونه باشه.</p>

<p><strong>"Recent Trends in Deep Learning Based Natural Language Processing"</strong> - <a href="https://arxiv.org/abs/1708.02709">1708.02709</a></p>

<p>Tom Young, Devamanyu Hazarika, Soujanya Poria, Erik Cambria</p>

<p>School of Information and Electronics, Beijing Institute of Technology, China; School of Computing, National University of Singapore, Singapore; Temasek Laboratories, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore</p>

<p>این مقاله به طور کلی به بررسی پیشینه، وضعیت فعلی، و روند پیشرفت روش‌های مبتنی بر شبکه‌های عصبی برای پردازش زبان‌های طبیعی پرداخته. اگر تازه می‌خوایید وارد این موضوع بشید یا حتی اگر می‌خوایید با تاریخچه و روال فعلی این موضوعات آشنا بشید این مقاله منبع خوبیه برای مطالعه‌ی اولیه.</p>

<p><strong>"Revisiting Unreasonable Effectiveness of Data in Deep Learning Era"</strong> - <a href="https://arxiv.org/abs/1707.02968">1707.02968</a></p>

<p>Chen Sun, Abhinav Shrivastava, Saurabh Singh, Abhinav Gupta</p>

<p>Google Research, Carnegie Mellon University</p>

<p>تا مدتی قبل بزرگ‌ترین مجموعه دادگان در دسترس عموم برای کلاسه‌بندی تصاویر مجموعه دادگان ImageNet بود.
ولی شرکت‌های بزرگ هر کدوم مجموعه دادگان خیلی بزرگ‌تری داشتن.
یکی از این مجموعه دادگان که مال گوگل هست JFT نام داره و حاوی بیش از ۳۰۰ میلیون(!) تصویر با ۱۸۲۹۱ دسته هست. البته برچسب‌زنی این همه تصویر به صورت خودکار انجام شده و بنابراین دارای خطا هستن. ولی با این حال اندازه‌ی این مجموعه دادگان واقعاً بزرگه.
توی این مقاله گوگلی‌ها بررسی کردن که آیا معماری‌های معمول دسته‌بندی تصاویر وقتی که تعداد تصاویر به مقدار قابل توجهی زیاد بشه باز هم می‌تونن به نتیجه‌ی بهتری دست پیدا بکنن و نمایش بهتری از داده‌ها رو یاد بگیرن؟
برای این کار یک مدل ResNet-101 رو روی این مجموعه دادگان آموزش میدن (در مورد جزئیات این آموزش توی مقاله نوشته شده) و بعد از این مدل آموزش دیده شده به عنوان مدل اولیه برای چهار downstream task دیگه استفاده می‌کنن، یعنی کلاسه‌بندی تصاویر، تشخیص اشیا، قطعه‌بندی معنایی تصاویر، و تشخیص وضعیت (اسکلت) انسان.
اونطوری که حدس زدن نتیجه‌ی این کار دور از انتظار نیست، مدل آموزش داده شده بر روی مجموعه تصاویر JFT-300M و بعد fine-tune شده روی هر مجموعه دادگان تونسته بهترین نتیجه رو توی هر کدوم از این چالش‌ها به دست بیاره.</p>

<p>چون کسی به غیر از گوگل به مجموعه دادگان به این بزرگی دسترسی نداره، تنها میشه امیدوار شد که گوگل مدل آموزش‌داده‌شده بر روی این مجموعه دادگان بزرگ رو منتشر بکنه (تا الان که این کار رو نکرده، بعید می‌دونم بعد از این هم بکنه).</p>

<p><strong>"Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge"</strong> - <a href="https://arxiv.org/abs/1708.02711">1708.02711</a></p>

<p>Damien Teney, Peter Anderson, Xiaodong He, Anton van den Hengel</p>

<p>Australian Centre for Visual Technologies, The University of Adelaide, Australia; Australian National University, Canberra, Australia; Deep Learning Technology Center, Microsoft Research, Redmond, WA, USA</p>

<p>این مقاله شرح روشی هست که در آخرین مسابقه‌ی پاسخ پرسش‌های تصویری VQA 2017 که بر روی نسخه‌ی دوم مجموعه دادگان VQA هم بود تونست مقام اول رو کسب بکنه.
تقریباً میشه با نگاهی به تصویر دوم در مقاله کلیت روش رو فهمید. نکات جالب این مدل به نظرم در مقایسه با مدل‌های دیگه برای VQA یکی روش استخراج ویژگی‌های تصویر هست که از R-CNN استفاده شده، و نکته‌ی بعدی هم استفاده از ضرب درایه به درایه برای ترکیب ویژگی‌های سوال و تصویر هست.
این کار تقریباً بر خلاف اکثر کارهای اخیر هست که توی اون‌ها تعامل‌های مرتبه بالاتری بین توصیف تصویر و سوال مدل‌سازی میشن، مثلاً انواع تعامل bilinear به جای ضرب هادامارد ساده. ولی خب در اینجا تونستن
البته کار جدیدی که توی این مدل انجام دادن و به خاطر ندارم مدل‌های دیگه‌ای این کار رو کرده باشن اینه که مسئله‌ی VQA رو (با در نظر گرفتن برچسب‌های این دیتاست) تبدیل کردن به یه مسئله‌ی دسته‌بندی چند برچسبی (Multi-label classification).
یه نکته‌ی خیلی عجیب در مورد این مقاله این هست که این شبکه با استفاده از MATLAB پیاده‌سازی و آموزش داده شده.</p>

<p>چیزی که باعث شد من خیلی از این مقاله خوشم بیاد، علاوه بر اینکه قسمت‌های مختلف کارشون رو خوب توضیح دادن، اینه که Ablation study خیلی مفصلی انجام دادن که دقیقاً تشریح می‌کنه هر قسمت از مدل‌شون و هر کاری که انجام دادن چقدر در رسیدن به نتیجه‌ی نهایی تاثیر داشته.
همین کار باعث میشه که اعتماد آدم به این کار و نتایجش تقریباً تضمین بشه. ولی اینکه کد این مقاله منتشر نشده و البته اگر هم منتشر بشه با MATLAB نوشته شده یکی از نکات منفی این کار هست، البته در مقابل نکات قوت این کار میشه کاملاً ازشون چشم‌پوشی کرد.</p>

<p>فکر می‌کنم از این به بعد اگر کسی بخواد روی مسئله‌ی VQA کار بکنه باید از این کار شروع بکنه.</p>

<p><strong>"MemexQA: Visual Memex Question Answering"</strong> - <a href="https://arxiv.org/abs/1708.01336">1708.01336</a></p>

<p>Lu Jiang, Junwei Liang, Liangliang Cao, Yannis Kalantidis, Sachin Farfade, Alexander Hauptmann</p>

<p>Carnegie Mellon University, Customer Service AI, Yahoo Research</p>

<p>این مقاله کار بسیار جالبی هست که توجه من رو خیلی جلب کرد و فکر می‌کنم چیزی هست که در آینده‌ی نزدیک خیلی دوست دارم روش کار بکنم.
این مقاله مسئله‌ی MemexQA رو معرفی می‌کنه.
این مسئله اینطوری تعریف میشه که اگر یک مجموعه از تصاویر و ویدیوها متعلق به یک فردی داده بشن، هدف اینه که به صورت خودکار به سوالات کاربر جواب بدیم تا کاربر بتونه خاطراتش رو در مورد رویدادهایی که اتفاق افتادن و توی اون مجموعه به تصویر کشیده شدن به خاطر بیاره.
مثلاً یه سری تصویر از یک جشن تولد دارید ولی به خاطر نمیارید که جشن تولد کی بوده.
هدف این کار اینه که این سیستم بتونه به این سوال که جشن تولد کی بوده پاسخ بده و برای پاسخش هم تعدادی تصاویر از اون مجموعه تصاویر به عنوان مدرک بیاره.
برای اینکار یک مجموعه دادگان جدید هم به همین اسم منتشر شده، البته در حال حاضر در دسترس نیست، ولی به زودی خواهد بود.
این مسئله و کلیت مقاله به نظرم خیلی جالب هستن و البته مدل اولیه‌ای که ارائه دادن خیلی مدل پیچیده‌ای نیست. بنابراین فکر می‌کنم میشه با مدل بهتری نتایج بهتری روی این مجموعه دادگان گرفت. در کل اگر به مسئله‌ی مطرح شده تو این مقاله علاقه دارید حتماً مقاله رو کامل بخونید.</p>

<p><strong>"TensorFlow Estimators: Managing Simplicity vs. Flexibility in High-Level Machine Learning Frameworks"</strong> - <a href="https://arxiv.org/abs/1708.02637">1708.02637</a></p>

<p>Heng-Tze Cheng, Zakaria Haque, Lichan Hong, Mustafa Ispir, Clemens Mewald, Illia Polosukhin, Georgios Roumpos, D Sculley, Jamie Smith, David Soergel, Yuan Tang, Philipp Tucker, Martin Wicke, Cassandra Xia, Jianwei Xie</p>

<p>Google; UptakeTechnologies</p>

<p>این یک مقاله‌ی خیلی جالبی هست که توی کنفرانس KDD 2017 پذیرفته شده و رابط برنامه‌نویسی <code>Estimator</code> رو در کتابخانه‌ی TensorFlow معرفی می‌کنه.
ساختاردهی و مدیریت کد یکی از کارهای سختیه که نیاز به تجربه‌ی زیادی داره.
ولی با این حال بعضی وقت‌ها کتابخانه‌ها می‌تونن با فراهم کردن رابط‌های برنامه‌نویسی خوب ساختاردهی مناسبی به کد کاربر اعمال بکنن.
یکی از این ساختاردهی‌ها توی کتابخانه‌ی TensorFlow با استفاده از کلاس <code>Estimator</code> اعمال میشه که در این مقاله به طور مفصلی در این مورد صحبت کرده.
از روی تجربه‌ام فکر می‌کنم دنبال کردن یک ساختار برنامه‌نویسی که سطح بالا است و در عین حال انعطاف‌پذیری کافی هم داره هم باعث میشه که پروژه سریع‌تر جلو بره و هم با گذشت زمان هم‌چنان کد قابل مدیریت باقی می‌مونه. حدود شش ماه پیش که تصمیم گرفتم آخرین پروژه‌ام رو با استفاده از کتابخانه‌ی TensorFlow شروع کردم خوشبختانه با نمونه کدی شروع کردم که از این رابط‌های برنامه‌نویسی مثل کلاس <code>Estimator</code> استفاده می‌کرد.
هر چند استفاده از این رابط‌ها هنوز معمول نیست بین برنامه‌نویس‌ها، ولی از این انتخاب بسیار راضی هستم. چون باعث شده که با وجود نیاز به تغییرات بنیادین و البته بزرگ‌شدن زیاد کد در طول پروژه، نیازی نباشه که کل کد رو چند بار از اول ساختاردهی بکنم و دوباره بنویسم و یا اینکه مشکلات بزرگی در کد پیش بیاد.</p>

<p>اگر می‌خوایید پروژه‌ای با اندازه‌ی متوسط به بالا با کتابخانه‌ی TensorFlow پیاده‌سازی بکنید پیشنهاد می‌کنم از رابط‌های برنامه‌نویسی کلاس‌های <code>Estimator</code> و <code>Experiment</code> استفاده کنید و این مقاله رو هم بخونید.</p>

<h2>پست‌های وبلاگ منتخب از هفته‌ی گذشته</h2>

<p><a href="https://www.edge.org/conversation/thomas_metzinger-benevolent-artificial-anti-natalism-baan">تولدستیزی مصنوعی خیرخواهانه!</a></p>

<p>این یه مطلب تقریباً مفصل هست در مورد یک سناریوی غیرمحتمل که البته بیشتر جنبه‌ی فکری داره، تا اینکه واقعاً امکانش وجود داشته باشه. به نوعی یک آزمایش ذهنی.</p>

<p>فرض کنید یک ابرهوش به وجود بیاد که توانایی ذهنی بسیار زیادی داره، خیلی بیشتر از توانایی ذهنی انسان‌ها.
بنابراین میشه نتیجه گرفت که این موجودیت توانایی بیشتری هم در زمینه‌ی استدلال در مورد اخلاق و آداب هم داره.
حالا فرض کنید که این موجودیت به انسان‌ها و زندگی کردن‌شون رو ببینه و بعد به این نتیجه برسه که اگر انسان‌ها به دنیا نیان، بنابراین نمی‌تونن رنجی رو هم متحمل بشن.
بنابراین خیلی خیرخواهانه تصمیم می‌گیره که سیاست تولدستیزی (Anti-Natalism) سیاست خیلی خوبی در مورد انسان‌هاست.</p>

      <!--<p><a href="/2017/08/arxiv-sat-20170812/">ادامه‌ی مطلب</a></p>-->
    </li>
    <hr/>
    <li class="post">
      <h1><a href="/2017/04/arxiv-saturdays/">arXiv Saturdays and the ever-growing list of unread papers</a></h1>
      <div class="meta">
        <p class="posted"><i class="fa fa-calendar"></i> 08 Apr 2017</p>
        <ul class="categories">
        <i class="fa fa-tag"></i>
          <li><a href="/category/Deep Learning" title="Deep Learning">Deep Learning</a></li>
          <li><a href="/category/Research" title="Research">Research</a></li>
        </ul>
      </div>
      
      <h1>به نام خدا</h1>

<p>For the past two years, or a little more, I have been following the latest research published on arXiv. I also check the proceedings of relevant conferences, but arXiv is my most important resources for following what is going on in the world of AI.</p>

<p>I am subscribed to the RSS feeds of some of the relevant arXiv sections (cs.CV, cs.LG, cs.NE, cs.CL, etc.). So all new entries are available in my feed reader of choice (Feedly). At first I didn't have a schedule to check the new entries, and sometimes entries got removed after 30 days. However, for the past few months, I follow a plan that helps me keep track of all the latest research. I have <strong>arXiv Saturdays</strong>, when I check all of the papers added to arXiv during the past week. Why Saturday? Because that's the only day no new entries are added to arXiv. This also helps with amortizing the time needed to check all these papers, since each week a large number of new papers are added to arXiv, for example today that I checked Feedly, there were 470 new entries!</p>

<p>As I scroll through the new entries, the first filter is the title of the paper. Judging by the title I can filter out most of the papers. If I find the title relevant to my own and some of my friends (more on the friends later) research, I move to read the paper's abstract. I not only check out the papers relevant to my own research interests, but I also check some that are relevant to the research interests of a number of my friends. If I find them relevant, I email the link to the article to them. I know that they now hate my emails, and I'm almost sure that they don't read most of them :D Anyway, it helps me get to know what is happening outside of my research interests. In addition to the abstracts, I also check the list of authors. I know that some of the authors publish on the same topics that I'm working on most of the time. If a paper passes through these papers, then it gets added to an special "list" on a Trello board that I call "Reading List". Papers stay on the "To Skim" list until I get back to them and then move them to the lists I have created for each project or topic. You can say that this reading list is quite big by now. Given that I have created this Trello board just months ago, I have started to feel that a Trello board might not have been the best choice for managing these number of items. However, so far I haven't found a replacement. In Trello, a card is created for each paper and it contains a link to the paper, sometimes a link to an implementation of the paper, and also a short summary or note I write about the paper from time to time. I also add labels to each card, which indicate whether I have already read the paper, is it work-related or not, what general topic does it belong to, and some other labels. However, you can't link cards to each other. As a result, you can't have a good ordering between a subset of papers. The problem is that to have proper ordering between papers, you need to have a graph, a simple list won't make it. That's why I still have problem ordering papers according to some features, around a central topic or research question.</p>

<p><img src="/stylesheets/images/reading-list-trello-board.png" alt="Reading List Trello board" /></p>

<p>To manage the actual articles, which I finally get to read, I use Mendeley. It is indeed a great service, it has a very good cross platform application and its document reader is quite functional. I am one of those who highlights papers heavily and in fact I have devised a color code for my highlights.</p>

<p><img src="/stylesheets/images/mendeley.png" alt="Highlighting papers in Mendeley" /></p>

<p>But in addition to reading the papers and highlighting them, I need somewhere to write other notes and sometimes try to work out the equations for myself once more. For that I use OneNote, one page for each paper.</p>

<p><img src="/stylesheets/images/onenote.png" alt="Taking notes in OneNote" /></p>

<p>The combination of Mendeley and OneNote works fine for the time being, although my cloud storage provided by Mendeley is filling up quickly.</p>

<p>Since I'm just a beginner, most of my time is spent reading other researchers' published work, but even now I feel that this process is not quite working. The discovery part is fine I think. I check out everything on arXiv. I also follow a large number of researchers and PhD students on Twitter and this stream is quite useful in staying on top of the best and latest research. The reading and taking note part is also a working combination. However, the managing and scheduling side of things is not close to being called "working". I still think that I need to find a better tool or combination of tools for managing the comparably large volume of research papers and schedule reading them. But all these stuff aside, it is really becoming very hard keeping up with the latest research. Checking out weekly papers on arXiv is a very time-consuming activity by itself, now imagine the list of accepted papers to a conference getting published! A true paper overflow.</p>

<p>How have you set up your research consumption workflow? How do you manage and schedule the ever-growing list of papers?</p>

      <!--<p><a href="/2017/04/arxiv-saturdays/">ادامه‌ی مطلب</a></p>-->
    </li>
    <hr/>
    <li class="post">
      <h1><a href="/2017/02/sourced/">پژوهش و همکاری با sourced</a></h1>
      <div class="meta">
        <p class="posted"><i class="fa fa-calendar"></i> 17 Feb 2017</p>
        <ul class="categories">
        <i class="fa fa-tag"></i>
          <li><a href="/category/Deep Learning" title="Deep Learning">Deep Learning</a></li>
          <li><a href="/category/NLP" title="NLP">NLP</a></li>
          <li><a href="/category/Research" title="Research">Research</a></li>
        </ul>
      </div>
      
      <h1>به نام خدا</h1>

<p>بعد از اینکه فرمان اجرایی ممنوعیت مهاجرت تبعه‌ی هفت کشور توسط ترامپ امضا شد، صحبتی با آقای Eiso Kant پیش اومد در مورد وضعیت پژوهش در ایران و مشکلاتش.
آقای Eiso Kant مدیرعامل و یکی از بنیان‌گذاران شرکت 
<a href="http://sourced.tech/">source{d}</a>
 هستن.
هدف این شرکت ساخت یک هوش مصنوعی هست که بتونه کد رو بفهمه. هدف بسیار جالبی هست و فکر می‌کنم خیلی کاربرد داشته باشه، حداقل برای کسایی که بلدن کد بزنن. البته هدف فراتر از این هم هست. برای اینکه بتونن به این هدف برسن لازمه که بتونن کد رو به خوبی بفهمن. به همین خاطر همه‌ی کدهای موجود در گیت‌هاب و بیت‌باکت رو گرفتن و تحلیل کردن، پس اگر کدی روی هر کدوم از این سایت‌ها داشتید که به صورت عمومی منتشر شده بود، جزو داده‌هایی که این شرکت جمع کرده و روشون تحلیل انجام داده قرار داشته. این شرکت کلی پروژه‌ی جالب رو به صورت متن‌باز منتشر کرده که یه پیاده‌سازی از 
<a href="https://github.com/src-d/go-git">git به زبان Go</a>
 و یک پیاده‌سازی الگوریتم خوشه‌بندی
 <a href="https://github.com/src-d/kmcuda">K-means بر روی کارت گرافیکی</a>
 جزو جالب‌ترین این پروژه‌ها از نظر من هستن.</p>

<p>خلاصه بعد از اینکه صحبت در مورد پژوهش شد ایشون پیشنهاد دادن که علاقه‌مند هستن با کسایی که در حال حاضر در ایران مشغول پژوهش هستن یا می‌خوان پژوهش جدی داشته باشن، در زمینه‌هایی که مرتبط به هدف شرکت باشه همکاری بکنن.
برای اینکه توضیحی در مورد شرکت و هدف‌شون داده باشن و جزئیات و شرایط این همکاری مشخص باشه، یه ارائه آماده کردن که
<a href="https://docs.google.com/presentation/d/1wUWs3nIlwLsosMW30-K8aaoEZYbp92XqEbkm0-VwsBk/edit?usp=sharing">تو این لینک</a>
می‌تونید ببینیدش.</p>

<p>من فکر می‌کنم که همچنین همکاری‌هایی می‌تونه خیلی مناسب باشه و یک تجربه‌ی آموزشی خیلی خوبی رو فراهم بکنه. پس اگر فکر می‌کنید که پیشنیازهای لازم رو دارید و در مورد پژوهش در این موضوعات جدی هستید (یا اگر حتی هنوز موضوع پایان‌نامه‌ی ارشدتون رو تعریف نکردید)، توصیه می‌کنم حتماً باهاشون تماس بگیرید. اگر سوال دیگه‌ای داشتید می‌تونید با من هم تماس بگیرید.</p>

      <!--<p><a href="/2017/02/sourced/">ادامه‌ی مطلب</a></p>-->
    </li>
    <hr/>
    <li class="post">
      <h1><a href="/2016/11/iqa-iclr2017/">Paper notes for &quot;A Context-aware Attention Network for Interactive Question Answering&quot;</a></h1>
      <div class="meta">
        <p class="posted"><i class="fa fa-calendar"></i> 19 Nov 2016</p>
        <ul class="categories">
        <i class="fa fa-tag"></i>
          <li><a href="/category/Deep Learning" title="Deep Learning">Deep Learning</a></li>
          <li><a href="/category/NLP" title="NLP">NLP</a></li>
          <li><a href="/category/Paper Notes" title="Paper Notes">Paper Notes</a></li>
        </ul>
      </div>
      
      <h1>به نام خدا</h1>

<p>I just read this paper that is submitted to ICRL 2017 and thought that I might write my notes as a post in the blog. It is a quite interesting and useful habit to publish these notes, but I have been a little lazy before. I'll try to publish more from now on.</p>

<h1>A Context-aware Attention Network for Interactive Question Answering</h1>

<p><a href="http://webpages.uncc.edu/~hli38/">Huayu Li</a>, Martin Renqiang Min, Yong Ge, Asim Kadav</p>

<p>Link(s): <a href="https://openreview.net/forum?id=SkyQWDcex">OpenReview</a></p>

<h2>Summary</h2>

<p>It is an extension of the encoder-decoder framework for the task of question answering, which has two levels of attention when encoding sentences of the story and also when encoding the words of each sentence. Although "attention" term is used throughout the paper, "importance weighting" would better convey the idea of the paper. In addition to this, the other novelty of the paper is introducing a feedback mechanism for when the model doesn't have enough information to generate a correct answer. To test their model's ability to ask question from a user and obtain feedback, they also introduce a new dataset based on bAbI, named "ibAbI".</p>

<h2>More in depth</h2>

<p>This architecture consists of three main modules:</p>

<ol>
<li>Question Module</li>
<li>Story Module</li>
<li>Answer Module</li>
</ol>

<p>Let's start by first looking at this figure from the paper.</p>

<p><img src="/stylesheets/images/iqa-figure2.png" alt="Figure 2 from paper schematically showing the three modules used in the network architecture" /></p>

<p>In the problem of textual question answering, we are given a question sentence and a sequence of story sentences. The goal is to find the answer to the question given the story sentences. Each sentence is a sequence of words.</p>

<h3>Question Module</h3>

<p>Given a question sentence as a sequence of words, $(\omega^q _ 1,\cdots,\omega _ {N _ q}^q)$, each word is first embedded using an embedding matrix \(\boldsymbol{W} _ \omega\). To achieve an encoding which takes the sequential nature of this sentence into account, a \(GRU _ \omega\) is used. Usually the last hidden state of the recurrent model is used as the encoding of a sequence. However, in this work, they use importance weighting (or "attention") to obtain the encoding of the sequence, using hidden states of the GRU throughout the sequence. To determine the importance of the hidden state at each time step, its similarity with a vector \(\mathbf{v}\) is used. This vector is learned jointly with the model. Although in general it doesn't look like a good idea to use a static vector to assess the importance of each word in a question sentence, however in this case, given mostly short questions, it seems to work. A better approach would be to use techniques like coattention, i.e. to use representation from the input sentences to assess the importance of words in the question sentence. In addition, it would be much better if results without this static attention were also reported, to show how much, if any, is this approach beneficial to the overall system. Anyways, after normalizing the "attention" weights using softmax, weighted some of hidden states is calculated and using a one-layer linear MLP, is projected into "context-level" vector space, thus</p>

<p>$$ \mathbf{u} = \mathbf{W} _ {ch} \sum _ {j=1}^{N _ q} \gamma _ j \mathbf{g} _ j ^ q + b _ c ^ {(q)} $$</p>

<p>So we have vector $\mathbf{u}$ as the vector representation of the question sentence.</p>

<h3>Input Module</h3>

<h4><strong>Sentence Encoder</strong></h4>

<p>"Input module aims at generating a representation for input sentences, including a sentence encoder
and a context encoder". Input module is given a number of sentences each containing $N _ t$ words. Sentence encoder will encode each sentence into a vector representation, and then the context encoder will encode the sequence of sentence embeddings into a sequence of contextual embeddings, embeddings that take context into account. Let's start from the sentence encoder. As usual each word is embedded first using the embedding matrix $\boldsymbol{W} _ \omega$ (embedding matrices are shared in all modules). Then using a GRU, $GRU _ \omega$, these embeddings are transformed into a sequence of hidden states, $(\mathbf{h} ^ t _ 1, \cdots, \mathbf{h} ^ t _ {N _ t}).$ After this, the important step of word-level attention occurs. What is important and one of the main novelties of this work, is that contextual information from previous sentences is used in this step. </p>

<p><img src="/stylesheets/images/sentence-enc-iqa.png" alt="A hand-drawn diagram of the sentence encoder" /></p>

<p>The diagram above is the missing figure from the paper! Well, just kidding. Figure 2 from paper is quite informative. This is just a supplementary diagram to make things more clear.</p>

<p>As can be seen in the figure above, after using a GRU's hidden states as preliminary representation of the input sentence words, a context vector from the last input sentence is used to transform hidden state representations to another representation which takes the overall context of previous sentences into account. For this transformation, a two layer MLP is used (Equation 5) to obtain the sequence of "context-injected" representations of sentence $l _ t$, $(\mathbf{e} ^ t _ 1, \cdots, \mathbf{e} ^ t _ {N _ t})$. Afterwards, vector representation of the question, $\mathbf{u}$, is used to obtain importance weighting of the words in the sentence and these weights, after being normalized, are used to get a weighted sum of the representations of words of sentence, $\mathbf{y} _ t$. This vector representation of sentence $l _ t$ not only has word-level attention, but also context from previous sentences have been taken into account.</p>

<p>A question that comes to mind is why this attention mechanism isn't incorporated inside the GRU itself? Although the current architecture has allowed the model to have shared parameters in GRUs when encoding the question, input sentences, and the feedback sentence, but it would be interesting to see how the model would perform if attention was baked into the GRU, like the Attentional GRU in the DMN+[1] paper.</p>

<h4><strong>Context Encoder</strong></h4>

<p>Context encoder simply uses another GRU, $GRU _ s$, to encode sequence of sentence representations from the sentence encoder into another sequence $(\mathbf{s} _ 1, \cdots, \mathbf{s} _ N)$. This lets the model encode the sequential structure into the representation obtained from the sentence encoder. Afterwards, just like the sentence encoder, inner product with question representation $\mathbf{u}$ is used to weight importance of each representation in the sequence of sentences. These weights are then used to get the input encoding vector $\mathbf{m}$ (Equations 8 and 9).</p>

<h3>Answer Module</h3>

<p>As clearly can be seen, this architecture is an extension of attention-less sequence to sequence models. It has the bottleneck vector representation $\mathbf{u} + \mathbf{m}$, which is used to condition the language model in the Answer Module. It doesn't have attention mechanism in the decoder, it only has the attention in the encoder portion of the architecture (similar to many VQA models). Although results are impressive (on the bAbI dataset), it would be interesting to see how this architecture (without the feedback mechanism) would fare against models that incorporate attention in their decoder.</p>

<p>The answer generation module is a language model that conditioned on the $\mathbf{u} + \mathbf{m}$ generates the answer to the question. However, the interesting part happens after this language model generates the first answer. There two EOS sentinel characters defined in this model, the question mark and the period. In case the generated sequence ends with a period, the model has decided that it has enough information to generate the answer to the question, given the input sentences. However, if the generated sequence ends with a question mark, it means that the model is asking for more feedback to be able to answer the question. After the model generates a question and gets a feedback, uses the representation of the feedback sentence, $\mathbf{f}$, to update its attention over the sequence of sentence embeddings. It is interesting that they use simple uniform importance weighting over the words of the feedback sentence to obtain its vector representation, instead of attention using the question representation, or the supplementary question generated by the model, or even only using the final state of the $GRU _ \omega$ used for processing the feedback sentence. The updated representation which is the sum of the question representation and the updated overall sentences representation is used to generate the final answer, given the feedback to the model. To simplify the model, they "allow the decoder to only generate at most one supplementary question". Although it may be tempting to allow the model to be able to ask more than one supplementary question, however since answer to these supplementary questions only would update the representation of the model of the input sentences, not increase model's overall knowledge, therefore it won't hurt much to limit the model to at most one supplementary question. The ability to increase model's knowledge using the feedback might make model more capable, although with increased complexity.</p>

<h3>Experiments</h3>

<p>They report that "training can be treated as a supervised classification problem" and they try "to minimize the cross-entropy error of
the answer sequence and the supplementary question sequence". 
The evaluate their model on the bAbI dataset and a newly proposed ibAbI (interactive bAbI) dataset. They compare their models with DMN+[1], MemN2N[2], and a simple EncDec[3] model. Their model successfully manages to solve 19 out of 20 of the bAbI tasks (Table 4). They also get significantly better results on the ibAbI dataset compared to the other models evaluated. </p>

<h3>Final words</h3>

<p>The paper was interesting, although short of some details. They could also compare their models against an additional number of other models. It would also be great if they could provide an open source implementation of the proposed model. I still can't think of a way to implement the Input Module. If you have any suggestions comment below.</p>

<p>[1] Caiming Xiong, Stephen Merity, and Richard Socher. Dynamic memory networks for visual and textual question answering. In ICML, pp. 2397–2406, 2016.</p>

<p>[2] Sukhbaatar Sainbayar, Szlam Arthur,Weston Jason, and Fergus Rob. End-to-end memory networks. In NIPS, pp. 2440–2448, 2015.</p>

<p>[3] Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning phrase representations using RNN encoder-decoder for statistical machine translation. In EMNLP, pp. 1724–1734, 2014.</p>

      <!--<p><a href="/2016/11/iqa-iclr2017/">ادامه‌ی مطلب</a></p>-->
    </li>
    <hr/>
    <li class="post">
      <h1><a href="/2016/01/office-365-student/">آفیس رایگان برای دانشجویان</a></h1>
      <div class="meta">
        <p class="posted"><i class="fa fa-calendar"></i> 20 Jan 2016</p>
        <ul class="categories">
        <i class="fa fa-tag"></i>
          <li><a href="/category/Education" title="Education">Education</a></li>
          <li><a href="/category/Software" title="Software">Software</a></li>
        </ul>
      </div>
      
      <h1>به نام خدا</h1>

<p>چون دانشجویان در سراسر دنیا قشر فقیری هست(!)، بخاطر همین خیلی از شرکت‌های نرم‌افزاری سعی می‌کنن بعضی از سرویس‌ها و نرم‌افزارهاشون رو با قیمت پایین یا به صورت رایگان به دانشجویان ارائه بکنن. نمونه‌اش مثلاً گیت‌هابه که پنج تا repository خصوصی به هر دانشجو میده، یا مثلاً شرکت Autodesk نرم‌افزار AutoCAD یا یه تعداد دیگه‌ای از نرم‌افزارهاش رو به صورت رایگان میده، شرکت Jetbrains اجازه‌ی استفاده از IDEهاش و البته Resharper رو به صورت رایگان میده و کلی چیز دیگه که اگر بگردید حتماً پیدا می‌کنید.</p>

<p>یکی دیگه از شرکت‌هایی که از قدیم کلی خدمات رایگان به دانشجوها میده شرکت Microsoft هست. این شرکت تحت برنامه‌ی <a href="https://dreamspark.com">Dreamspark</a> یه سری از خدمات رو از سال‌ها قبل ارائه میداد، خدماتی مثل Windows Server، SQL Server، Microsoft R Server و البته خدماتی با همکاری شرکت‌های دیگه مثل Github و Xamarin و یه مدت استفاده از آموزش‌های سایت Pluralsight. قدیم‌ها هم که ویژوال استودیو کلاً نسخه‌ی رایگان نداشت، نسخه‌ی Professional ویژوال استودیو رو هم میشد از طریق این برنامه گرفت. ولی الان که نسخه‌ی رایگان Community به نسخه‌های ویژوال استودیو اضافه شده نیاز به این خدمت کم شده. راستی اخیراً هم اکانت رایگان Azure به کاتالوگ خدمات Dreamspark اضافه شده که البته فعلاً نمیشه از ایران فعالش کرد. باید صبر کرد ببینیم این مشکل رو حل می‌کنن یا نه.</p>

<p>قبلاً از طریق برنامه‌ی Dreamspark میشد تخفیف برای خرید subscription آفیس 365 گرفت، ولی این رو برداشتن. </p>

<p>به جاش الان آفیس 365 به صورت رایگان به دانشجوها داده میشه!! :)</p>

<p>شاید یک سال قبل (یا کمتر یا بیشتر، دقیق یادم نیست) بود که اعلام شد مایکروسافت به دانشجوها subscription آفیس 365 رو به صورت رایگان ارائه خواهد داد. برای اینکار هم نیاز به این دارید که آدرس ایمیل از طرف دانشگاه با دامنه‌ی .edu داشته باشید. </p>

<p>مشکل این بود که این امکان برای ایران نبود، یعنی با ایمیل دانشگاه‌های ایرانی نمیشد این کار رو کرد. ولی امروز به صورت اتفاقی دوباره سعی کردم این کار رو بکنم و موفق شدم. یعنی احتمالاً مدتی هست که این امکان فراهم شده و بالاخره از اینجا با ایمیل دانشگاه‌های ایرانی هم میشه آفیس 365 رو گرفت. برای اینکار کافیه به ا<a href="https://products.office.com/en-us/student/office-in-education">ین آدرس</a>  برید و با وارد کردن ایمیل دانشگاهی‌تون حساب آفیس 365 رو دریافت کنید. با این کار یک ترابایت فضای رایگان روی OneDrive می‌گیرید. بعد می‌تونید نرم‌افزار آفیس رو بدون نیاز به کرک کردن استفاده کنید (البته من رو نسخه‌ی Office Standard امتحان کردم، چون این برنامه شامل نرم‌افزارهای Word، PowerPoint، OneNote و Excel میشه) نسخه‌های دیگه شامل نرم‌افزارهای دیگه‌ای هستن که توی این توافقنامه نیستن. در ضمن با این کار میشه آفیس رو روی 5 تا از کامپیوترهاتون استفاده کنید (PC و Mac) (توجه کنید روی کامپیوترهاتون، نه روی کامپیوتر خودتون و کسای دیگه، این License فقط به یک شخص حقیقی داده میشه). بعد روی موبایل و تبلت‌تون هم می‌تونید ازش استفاده کنید (روی همه‌ی سیستم‌عامل‌ها).</p>

<p><strong>سلب مسئولیت</strong> (فارسی همون Disclaimer): من این کارها رو با ایمیل دانشگاهی که توش مشغول تحصیل هستم (دانشگاه شریف) امتحان کردم، در مورد دانشگا‌ه‌های دیگه‌ی ایران اطلاعی ندارم.</p>

      <!--<p><a href="/2016/01/office-365-student/">ادامه‌ی مطلب</a></p>-->
    </li>
    <hr/>
    <li class="post">
      <h1><a href="/2015/09/new-address/">آدرس جدید!</a></h1>
      <div class="meta">
        <p class="posted"><i class="fa fa-calendar"></i> 05 Sep 2015</p>
        <ul class="categories">
        <i class="fa fa-tag"></i>
          <li><a href="/category/General" title="General">General</a></li>
        </ul>
      </div>
      
      <h1>به نام خدا</h1>

<p>راستی آدرس اینجا هم تغییر کرده. یعنی علاوه بر اینکه میشه با آدرس قبلی <a href="http://erfannoury.github.io">http://erfannoury.github.io</a> به اینجا دسترسی پیدا کرد، حالا آدرس <a href="http://blog.erfan.xyz">http://blog.erfan.xyz</a> هم اضافه شده. با این آدرس هم میشه به بلاگ دسترسی پیدا کرد. </p>

      <!--<p><a href="/2015/09/new-address/">ادامه‌ی مطلب</a></p>-->
    </li>
    <hr/>
    <li class="post">
      <h1><a href="/2015/09/installing-theano-2/">نصب کتابخانه‌ی Theano در ویندوز (به‌روزرسانی)</a></h1>
      <div class="meta">
        <p class="posted"><i class="fa fa-calendar"></i> 04 Sep 2015</p>
        <ul class="categories">
        <i class="fa fa-tag"></i>
          <li><a href="/category/AI" title="AI">AI</a></li>
          <li><a href="/category/Deep Learning" title="Deep Learning">Deep Learning</a></li>
          <li><a href="/category/Machine Learning" title="Machine Learning">Machine Learning</a></li>
          <li><a href="/category/Python" title="Python">Python</a></li>
        </ul>
      </div>
      
      <h1>به نام خدا</h1>

<p>بعد از پست قبلی در مورد نصب Theano بر روی ویندوز، تغییرات زیادی در این زمینه و کتابخانه‌های یادگیری عمیق و وضعیت نصب اونها روی ویندوز ایجاد شده. این پست به نوعی به‌روزرسانی بر روی موضوع نصب این کتابخانه‌ی پایه‌ای و بعد معرفی یک کتابخانه‌ی جدیده.</p>

<h2>نکات جدید برای نصب Theano</h2>

<p>چند روز پیش می‌خواستم این کتابخانه رو روی یک کامپیوتر جدید نصب کنم.
اولین کاری که کردم دانلود کردن و نصب Anaconda Python، CUDA 7.0 و البته Visual Studio 2013 بود. بخاطر اینکه هنوز CUDA از Visual Studio 2015 پشتیبانی نمی‌کنه، سراغ نسخه‌ی جدیدش نرفتم.
بعد از اینکه اینا رو نصب کردم (اول ویژوال استودیو، بعد پایتون، در نهایت کودا) رفتم سراغ نصب gcc. درسته که برای کامپایل‌کردن قسمت اصلی کد Theano از کامپایلر مایکروسافت استفاده میشه، ولی بعضی از تیکه‌های کد نیاز به gcc دارن.
برای اینکار <a href="http://tdm-gcc.tdragon.net/">TDM GCC</a> رو دانلود و نصب کردم. این نسخه از بقیه زودتر آپدیت میشه و چیز اضافی‌ای هم نصب نمی‌کنه.
بعد از اینکه همه‌ی اینها رو نصب کردم و مطمئن شدم که همه‌ی چیزهای لازم در مسیر سیستم قرار گرفتن رفتم سراغ نصب Theano.</p>

<p>اولین مشکلی که خوردم این بود که وقتی از gcc می‌خواست استفاده کنه خطای عدم وجود فایل‌های لازم برای پایتون رو میداد. رفتم خوب مسیر پایتون (پوشه‌ی libs) رو بررسی کردم. دیدم که همه چیز درسته.
بعد از کمی جستجو، فهمیدم که gcc نیاز به فایل‌های کتابخانه‌ای با فرمت <code>libpython27.a</code> داره، نه <code>python27.lib</code>. بنابراین باید اول این فایل رو پیدا (یا درست) می‌کردم و بعد در همون پوشه قرار میدادم. بعد از اینکار یکی از مشکلات کامپایل حل شد.
برای حل مشکل به <a href="https://github.com/Theano/Theano/issues/2867">این لینک</a> یه نگاهی بندازید.</p>

<p>مشکل دیگه یه مشکل خیلی عجیب بود. اینکه <code>C:\Windows\System32</code> تو مسیرهای سیستمی نبود. خیلی عجیب بود این موضوع برام و باعث ایجاد کلی مشکل و گرفتن کلی وقت شد. ولی بعد از اضافه کردن مسیر، کتابخانه به صورت کامل کامپایل شد.</p>

<p>بعد از این، نوبت درست کردن فایل تنظیمات کتابخانه، یعنی <code>.theanorc</code> بود. این رو هم در مسیر کاربری قرار دادم و بعدش رفتم سراغ اجرای کتابخانه که بدون مشکل اجرا شد. اینجا به عنوان مرجع، محتوای فایل تنظیمات Theano رو میذارم.</p>

<pre><code>[blas]
ldflags =
[nvcc]
flags=-LC:\Anaconda\libs
compiler_bindir=C:\Program Files (x86)\Microsoft Visual Studio 12.0\VC\bin
optimizer_including=dnn
fastmath = True
[global]
device = gpu
floatX = float32
[cuda]
root=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
</code></pre>

<p>البته اگر خوب ببینید قسمت blas خالیه. برای اون قسمت هم کتابخانه‌ی OpenBLAS رو دانلود کردم و مسیر اون کتابخانه و همچنین اسم فایل کتابخانه‌ی OpenBLAS رو به عنوان ورودی دادم.</p>

<p>بعد از این مراحل فکر نمی‌کنم مشکلی در نصب Theano پیش بیاد.</p>

<p>اون <strong>dnn</strong> هم که نوشتم همون cuDNN هست که انویدیا عرضه کرده تا محاسبات مرتبط با یادگیری عمیق سریعتر بشه. نصب اون هم راحته. بعد از اینکه فایل‌هاش رو دانلود کردید، تو پوشه‌های مرتبط توی محل نصب CUDA قرارشون بدید و اینجا هم اون خط رو به فایل تنظیمات اضافه کنید. cuDNN 2 روی ویندوز بدون مشکل کار می‌کنه، ولی cuDNN 3 رو هنوز امتحان نکردم.</p>

<h2>کتابخانه‌ی <a href="https://github.com/fchollet/keras">Keras</a></h2>

<p>کتابخانه‌ی یادگیری عمیق Keras یکی از اون کتابخانه‌های یادگیری عمیقه که به نظر میاد آینده‌ی بسیار درخشانی داشته باشه. این کتابخانه روی Theano ساخته شده، ولی API اون از Torch7 الهام گرفته شده و خیلی خوش‌دسته. برخلاف پیچیدگی‌های بالای کار با Theano، کد مربوط به این کتابخانه خیلی خوانا است و به راحتی می‌تونید توش به طراحی مدل و آموزش و تحلیل مدل بپردازید. واقعاً بین همه‌ی کتابخانه‌های یادگیری عمیقی که بررسی کردم (برای پایتون البته)، این بهترین گزینه برای شروع کاره. آموزش‌ها و راهنمایی‌های بسیار خوبی هم تو <a href="http://keras.io/">این آدرس</a> گذاشتن. حتماً اگر تصمیم دارید کار روی یادگیری عمیق رو بدون مشکلات زیاد شروع کنید نگاهی به این کتابخانه بندازید.</p>

<p>در کل بخاطر اینکه افراد و شرکت‌های زیادی پشت کتابخانه‌های Caffe و Torch7 بودن بقیه‌ی کتابخانه‌ها تقریباً عقب مونده بودن. ولی اخیراً احساس می‌کنم که کتابخانه‌های مبتنی بر Theano دارن جایگاه خودشون رو قوی‌تر می‌کنن. خیلی از مقالات اخیر با این کتابخانه‌های پیاده‌سازی شدن و همچنین پیاده‌سازی مقالات زیادی توسط افراد ثالث برای این کتابخانه‌ها انجام می‌گیره.</p>

<p>هر چقدر گزینه‌ها برای کار کردن زیاد باشن، بهتره. امیدوارم که روز به روز کتابخانه‌ها پیشرفته‌تر و البته ورود به اون‌ها ساده‌تر بشه.</p>

<p>فکر می‌کنم در روزهای آتی پست‌های متعددی داشته باشم.</p>

      <!--<p><a href="/2015/09/installing-theano-2/">ادامه‌ی مطلب</a></p>-->
    </li>
    <hr/>
    <li class="post">
      <h1><a href="/2015/03/code-org/">Code.org</a></h1>
      <div class="meta">
        <p class="posted"><i class="fa fa-calendar"></i> 24 Mar 2015</p>
        <ul class="categories">
        <i class="fa fa-tag"></i>
          <li><a href="/category/Programming" title="Programming">Programming</a></li>
        </ul>
      </div>
      
      <h1>به نام خدا</h1>

<p>شاید اسم برنامه‌ی «ساعتی با کد» یا "Hour of Code" رو شنیده باشید. هدف این برنامه اینه که در طی یک ساعت، تجربه‌ی ایجاد برنامه رو به افراد مختلف ارائه بکنه.<br />
سایت <a href="http://code.org">Code.org</a> که موسس آن <a href="http://code.org/about/leadership/hadi_partovi">هادی پرتوی</a> هست، مجری این برنامه در جهان هست. در این سایت افراد می‌تونن در قالب کاراکترهای مشهوری مانند پرنده‌های بازی Angry Birds یا کاراکترهای انیمیشن Frozen تکه‌کدهایی بنویسن و تجربه‌ی برنامه‌نویسی رو داشته باشن. دوره‌ی اول کدنویسی در این سایت که حداکثر شاید یک ساعت طول بکشه یک برنامه‌ی مفرح و شاد هست که
فرد در طی اون در قالب یک محیط بازی، حرکت کاراکتر رو با استفاده از بلوک‌های اجرایی به عنوان تکه‌های کد، ایجاد می‌کنن.
در این محیط فرد با استفاده از برنامه‌نویسی بلوکی، به جای نوشتن کد به صورت متن، با استفاده از کدهایی منطق بازی رو پیاده‌سازی می‌کنه. در طی این یک ساعت مفاهیمی مثل خط‌به‌خط اجرا شدن کد، تکرار در کد (loop) و همچنین شرط در اجرای کد آموزش داده میشن. بدلیل سادگی محیط، تموم‌کردن ساعتی با کد حتی برای بچه‌ها هم ممکنه و فکر می‌کنم براشون لذت‌بخش باشه.
نکته‌ی جالبی که در مورد این برنامه هست اینه که نزدیک 108 میلیون نفر که بیشتر دانش‌آموز هستن تا به حال این برنامه رو انجام دادن و این برنامه از طرف افراد مهمی در تکنولوژی مثل بیل گیتس، استیو بالمر و مارک زاکربرگ تبلیغ و حمایت میشه. افراد مختلفی از قشرهای مختلف هم در فیلم‌های آموزشی این برنامه وجود دارن. مثلاً آموزش اولیه رو یک خانم مدل که برنامه‌نویس هم هست میده، یا شرط‌ها رو یک بسکتبالیست تدریس می‌کنه. این عمومیتی که در آموزش‌ها نمایش داده میشه به مردم نشون میده که هر کسی می‌تونه کد بنویسه و کسایی که کد می‌زنن آدمای عجیب‌غریبی نیستن. این بخصوص می‌تونه به دانش‌آموزها دید خوبی بده تا شاید حاضر بشن در آینده به علوم کامپیوتر بپردازن. با توجه به سیر تغییر دنیا، به نظر میرسه که آینده به مهندسان کامپیوتر بیش‌ازپیش نیاز خواهد داشت. حتی اگر کسی مهندس کامپیوتر هم نشد، باید حداقل سواد و شناختی در مورد  سیستم‌های کامپیوتری که در همه‌جا وجود دارن داشته باشن.</p>

<p>انجام این برنامه رو به خواهرم پیشنهاد دادم و بعد از اتمام موفقیت‌آمیز این برنامه، این مدرک بهش داده شد که باعث شد هم خوشحال بشه و هم مشتاق‌تر بشه و تصمیم بگیره که بقیه‌ی دوره‌های برنامه‌نویسی این سایت رو انجام بده.</p>

<p><img src="/stylesheets/images/codeorg-hour-of-code-cert.jpg" alt="Code.org Hour of Code certificate" /></p>

<p>من هم پیشنهاد می‌کنم این سایت رو به بچه‌های فامیل و آشنا و هر کسی که مشتاق باشه و یا از وسایل کامپیوتری استفاده بکنه معرفی بکنید، مطمئنم خیلی لذت خواهند برد و خیلی چیزها هم یاد خواهند گرفت.</p>

<p>یک نکته‌ی مثبت دیگه هم اینه که این سایت نسخه‌ی فارسی هم داره. یادتون باشه از پایین صفحه زبان رو فارسی انتخاب کنید تا همه‌ی نوشته‌های سایت فارسی بشن. همچنین در این صورت زیرنویس ویدیوها هم فارسی میشه.</p>

<p>امیدوارم که با همچین برنامه‌هایی، سواد عمومی از کامپیوترها حداقل در نسل آینده بیشتر باشه و کامپیوتر و گوشی و اینترنت رو فقط مساوی با وایبر و بازی‌هایی مثل Clash of Clans ندونیم (این دو تا رو گفتم چون فکر می‌کنم اینا بیشترین مصرف رو در جامعه‌ی ایران داشته باشن)</p>

      <!--<p><a href="/2015/03/code-org/">ادامه‌ی مطلب</a></p>-->
    </li>
    <hr/>
    <li class="post">
      <h1><a href="/2015/03/ceemple-opencv-vs-extension/">OpenCV آسان در ویندوز با استفاده از Ceemple</a></h1>
      <div class="meta">
        <p class="posted"><i class="fa fa-calendar"></i> 20 Mar 2015</p>
        <ul class="categories">
        <i class="fa fa-tag"></i>
          <li><a href="/category/Ceemple" title="Ceemple">Ceemple</a></li>
          <li><a href="/category/Computer Vision" title="Computer Vision">Computer Vision</a></li>
          <li><a href="/category/OpenCV" title="OpenCV">OpenCV</a></li>
        </ul>
      </div>
      
      <h1>به نام خدا</h1>

<h2>OpenCV</h2>

<p>یکی از مهم‌ترین کتابخانه‌های پردازش تصویر و بینایی ماشین، کتابخانه‌ی <a href="http://opencv.org">OpenCV</a> هست. این کتابخانه که با استفاده از C/C++ نوشته شده و بسیاری از الگوریتم‌های مورد نیاز برای پردازش تصویر، بینایی ماشین و یادگیری ماشین رو پیاده‌سازی کرده. این کتابخانه از بسیاری از سیستم‌های عامل و معماری‌های سخت‌افزاری پشتیبانی می‌کنه و تقریباً همه جا می‌تونید ازش استفاده بکنید. همچنین اگر با زبان C++ راحت نباشید، این کتابخانه رو میشه به راحتی از زبان‌های جاوا و پایتون هم صدا زد و استفاده کرد.</p>

<p>با توجه به اینکه این کتابخانه از نظر حجم کد و همچنین وابستگی‌های خارجی به کتابخانه‌های دیگه، یک کتابخانه‌ی بسیار بزرگ به حساب میاد، بنابراین آماده‌کردن اون برای استفاده کار نسبتاً سختیه. برای اینکه بتونید از این کتابخانه استفاده بکنید، لازمه که کد این کتابخانه، به همراه کتابخانه‌های خارجی دیگری که کد به اونها وابسته هست کامپایل بشن تا بعد بشه ازشون استفاده کرد. این کار، بخصوص بر روی ویندوز نسبتاً سخت و وقت‌گیر هست. در این پست قصد دارم راه‌حل آسانی رو برای حل این مشکل معرفی کنم. OpenCV سخت در ویندوز رو بعداً توضیح خواهم داد.</p>

<h2>Ceemple OpenCV for Visual Studio</h2>

<h3><a href="http://www.ceemple.com/ceemple-opencv-visual-studio/">دریافت این افزونه</a></h3>

<p><img src="http://www.ceemple.com/wp-content/uploads/2015/01/Capture5-1024x555.png" alt="Ceemple OpenCV for Visual Studio" /></p>

<p><a href="http://ceemple.com">Ceemple</a> یک راه‌حل مناسب برای این مشکل ارائه داده. اونا یک extension برای ویژوال استودیو ارائه دادن که شامل OpenCV 3.0 کامپایل‌شده و آماده‌ی استفاده به همراه کتابخانه‌های جانبی مهمی مثل CUDA، OpenCL، OpenMP و IPP هست.
شاید اطلاع داشته باشید که خود OpenCV هم DLLهای از پیش‌ساخته‌شده‌ی کتابخانه رو برای ویندوز ارائه میده. ولی این فایل‌ها، با حداقل استفاده از کتابخانه‌های جانبی بخصوص CUDA و IPP ارائه میشن که این موضوع باعث میشه این کتابخانه از تمام امکانات سخت‌افزاری برای پردازش بهره نبره. ولی در نسخه‌ای که Ceemple ارائه میده، این کتابخانه‌های مهم جانبی وجود دارن و شما می‌تونید از سرعت بیشتر اجرای کد بر روی پردازنده‌ یا پردازنده‌ی گرافیکی خودتون استفاده کنید.</p>

<p>همچنین با نصب این افزونه، امکان ساخت پروژه‌های OpenCV به صورت مستقیم از درون ویژوال استودیو ایجاد میشه. به این ترتیب خیلی سریع و بدون نیاز به تنظیم دسترسی پروژه به فایل‌های header و dll و lib مربوط به OpenCV و کتابخانه‌های جانبی، می‌تونید شروع به کد زدن بکنید و به تولید برنامه بپردازید.</p>

<p><img src="http://www.ceemple.com/wp-content/uploads/2015/01/Capture.png" alt="New OpenCV project dialoge in VS" /></p>

<p>علاوه بر نکات مثبت گفته شده، با نصب این افزونه، افزونه‌ی <a href="https://visualstudiogallery.msdn.microsoft.com/e682d542-7ef3-402c-b857-bbfba714f78d">Image Watch</a> هم بر روی ویژوال استودیو نصب میشه. این افزونه‌ی بسیار مفید به شما در هنگام debug کردن برنامه در ویژوال استودیو کمک می‌کنه. با استفاده از این افزونه، در هنگام debug کردن، می‌تونید تصاویری که در کدتون استفاده می‌کنید و بر روی حافظه هستن رو ببینید و به راحتی به جریان کدتون پی ببرید و مشکلات احتمالی رو به راحتی پیدا و رفع کنید. این افزونه بسیار افزونه‌ی مفیدیه و برای کارهای پردازش تصویر و بینایی ماشین بسیار توصیه میشه.
(<a href="http://channel9.msdn.com/posts/Introducing-Image-Watch">توضیح بیشتر در مورد Image Watch</a>)</p>

<p><img src="http://www.ceemple.com/wp-content/uploads/2015/01/Capture7-1024x559.png" alt="Image Watch VS extension" /></p>

<p><strong>توجه</strong>: <em>تصاویر برگرفته از سایت <a href="http://ceemple.com">ceemple</a> هستند.</em></p>

<h2>به‌روزرسانی 1</h2>

<p>با استفاده از biicode هم می‌تونید به سادگی از OpenCV استفاده کنید. در این
<a href="http://docs.opencv.org/master/d3/d82/tutorial_biicode.html">لینک</a> در این مورد توضیح داده شده. </p>

      <!--<p><a href="/2015/03/ceemple-opencv-vs-extension/">ادامه‌ی مطلب</a></p>-->
    </li>
    <hr/>
  </ul>

  <!-- Pagination links -->
  <div id="post-pagination" class="pagination">



      <!--<a href="/">صفحه‌ی قبلی</a>-->

    <p class="previous">
      <a href="/page2">صفحه‌ی بعدی | Next page</a>
    </p>

  </div>

                </div>
                <!-- #content -->
            </div>
            <!-- #primary .site-content -->
        </div>
        <!-- #main -->

        <footer class="site-footer" role="contentinfo">
            <div class="site-info">
            قدرت گرفته از <a href="https://github.com/Sandra/Sandra.Snow" rel="generator">Sandra.Snow</a>. تِم تغییر یافته از روی Snow Byte. میزبانی بر روی صفحات  <i class="fa fa-github fa-lg" style="color: black"></i>  با  <i class="fa fa-heart fa-lg" style="color: red"></i>
            </div>
            <!-- .site-info -->
            <!--heap analytics badge-->
            <div>
                <a href="https://heapanalytics.com/?utm_source=badge"><img style="width:108px;height:41px" src="//heapanalytics.com/img/badgeLight.png" alt="Heap | Mobile and Web Analytics" /></a>
            </div>
        </footer>
        <!-- #colophon .site-footer -->
    </div>
    <!-- #page .hfeed .site -->
    <script src="http://ajax.aspnetcdn.com/ajax/jquery/jquery-1.9.0.min.js"></script>
    <script src='/javascripts/prettify.js' type='text/javascript'></script>

    <!--<script type="text/javascript">
var _gaq = _gaq || [];

_gaq.push(['_setAccount', 'UA-56885931-1']);
_gaq.push(['_trackPageview']);
        
(function () {
    var ga = document.createElement('script');
    ga.type = 'text/javascript';
    ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(ga, s);
})();
</script>-->

    <script type='text/javascript'>
      $(function () {
        $("pre code").parent().each(function () {
          if (!$(this).hasClass("prettyprint")) {
            $(this).addClass("prettyprint");
            a = true
          }
        });

        prettyPrint();
      });
    </script>
    <script type="text/javascript" src="/javascripts/bidiweb.build.js"> </script>
    <script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function()
    {
        bidiweb.style('.site-content  *');
    });
    </script>
</body>
</html>
