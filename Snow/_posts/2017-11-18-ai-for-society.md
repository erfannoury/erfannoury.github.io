---
layout: post
category: Aritifical Intelligence, Society
title: هوش مصنوعی برای جامعه
---
به نام خدا
===========

فکر کنم دور از ذهن نیست اگر بقیه‌ی مطالب این وبلاگ رو خونده باشید بدونید که مهم‌ترین زمینه‌ای که روش تمرکز دارم در حال حاضر هوش مصنوعی هست. از زمانی که تورینگ مقاله‌ی «ادوات محاسبه‌گری و هوش»[۱]
رو منتشر کرد ۶۸ سال می‌گذره. تو این مدت زمان خیلی اتفاق‌ها افتاده و هوش مصنوعی خیلی سرد و گرم کشیده. ولی حالا زمانی هست که بیشتر از هر وقت دیگه‌ای آدم‌های کارپشته و تازه‌کارهایی مثل من وارد این حوزه شدن. شاید بشه گفت الان مهم‌ترین تکنولوژی حاضر بشر هست که داره به شکوفایی میرسه. احتمالاً برای همه هم واضح باشه که تو چهار پنج سال اخیر پیشرفتش قابل مقایسه با قبل نبوده. حالا کاملاً از دانشگاه‌ها خارج شده و توی جامعه دنبال میشه و به طور مستقیم به اکثر جوامع تاثیر می‌گذاره.

احتمالاً اگر دسترسی به اینترنت داشته باشید، در مورد این هم اطلاع دارید که کلی آدم دارن در مورد این صحبت می‌کنن که اگر بتونیم به هوش عمومی مصنوعی [۲] برسیم، به احتمال زیادی نسل بشر منقرض خواهد شد. در مقابل یه سری هم هستن که میگن اگر به هوش عمومی مصنوعی برسیم دیگه زندگی انسان‌ها تبدیل به بهشت خواهد شد. به هر دو دسته‌ای که زمان حال یا آینده‌ی نزدیک رو ول کردن و دارن در مورد آینده‌ی نامعلوم دست‌یابی به هوش عمومی مصنوعی صحبت می‌کنن، میگن تکینه‌گراها [۳]، کسایی که غالباً خیلی احساسی و تعصبی در مورد این مسائل صحبت می‌کنن. البته حرف‌هاشون خیلی بیهوده هم نیست، واقعاً این خطر به شکل جدی وجود داره. ولی معمولاً وسط این حرف‌های اغراق‌آمیز در مورد یک آینده‌ی نامعلوم و شاید نه چندان نزدیک، اهمیت زمان حال و آینده‌ی خیلی نزدیک خیلی گم میشه. اون قدری که به حرف‌های تکینه‌گراها گوش داده میشه و کار انجام میشه، کار در مورد اثرات هوش مصنوعی بر روی جوامع و انسان‌ها انجام نمیشه.

شاید آخرین تکنولوژی خیلی مخربی که بشر بهش دست یافته باشه تکنولوژی تولید سلاح‌های هسته‌ای باشه. معمولاً وقتی در مورد خطرات هوش عمومی مصنوعی صحبت میشه، حتماً حرف سلاح‌های هسته‌ای هم وسط میاد. ولی فکر می‌کنم تفاوت عمده‌ای بین این دو تکنولوژی وجود داره که زیاد بهش توجه نمیشه. اگر یک دولت، مثل دولت امریکا، با یه پروژه‌ی خیلی بزرگ مقیاس مثل پروژه‌ی منهتن تونست به این تکنولوژی دست پیدا بکنه و بعد از سال‌ها این تکنولوژی فقط دست «دولت»های معدودی هست، نشون میده که موانع ورود به این حوزه خیلی خیلی بزرگ هستن.
ولی، موانع ورود به حوزه‌ای مثل هوش مصنوعی اصلاً اونقدر بزرگ نیستن. درسته برای یه چند تا دانشجو خریدن کارت گرافیکی سخت باشه، ولی هم‌زمانی وجود اینترنت، وجود داده، وجود زیرساخت‌های محاسباتی، و حرکت ارزشمند open source و مشابه اون در به اشتراک گذاری تحقیقات، یک هم‌زمانی منحصربفرد هست.
فکر کنید به جای اینکه پروژه‌ی منهتن یک پروژه‌ی مخفی باشه، با چند نفر محدود که روش کار می‌کردن، این یه حرکت بین‌المللی باشه بین تعداد زیادی آدم و شرکت، که کلی امکانات در اختیار دارن و آزادانه همه‌ی نتایج و دستاوردها رو به اشتراک میذارن. مثلاً فرض کنید اپنهایمر به یه چیز جدید در مورد تکنولوژی هسته‌ای میرسه، بعد میشینه آخر هفته یه مقاله می‌نویسه، جمعه شب (یا به طور مشابه یک‌شنبه شب) مقاله رو به آرکایو [۴] سابمیت می‌کنه و دو روز بعد، صبح دانشمندان روسی یا آلمانی که از خواب بیدار میشن میرن مقاله‌ی اپنهایمر و دوستان رو دانلود می‌کنن و از آخرین دستاوردهاشون در مورد ساخت سلاح‌های هسته‌ای استفاده می‌کنن. تصور می‌کنید این شرایط رو؟ این شرایط برای هوش مصنوعی وجود داره. ولی اتفاقات کوتاه مدتی که توی هوش مصنوعی میوفته به اندازه‌ی یک سلاح هسته‌ای صدا نمی‌کنن. خیلی کوچک‌تر هستن. یک سلاح هسته‌ای تاثیر مخربی رو جمعیت نسبتاً کمی (نسبت به جمعیت کل جهان) میذاره. ولی یک محصولی که هوش مصنوعی داشته باشه می‌تونه تاثیر خیلی کمی روی جمعیت خیلی بزرگی بذاره. تاثیرش هم معمولاً روی هر فرد به اندازه‌ای کمه که هیچ کسی رو از اتفاقی که داره میوفته خبردار نمی‌کنه.
مشکل اصلی هوش مصنوعی دقیقاً چیزی هست که باعث شده به این وضعیت پیشرفته‌ی فعلیش برسه، راحتی پیشبردش.

اول این ویدیو رو ببینید:

<div style="text-align:center;">
<iframe style="display:block" width="1280" height="720" src="https://www.youtube-nocookie.com/embed/xhp47v5OBXQ?rel=0" frameborder="0" allowfullscreen></iframe>
</div>

شاید اول فکرتون به این سمت بره که اگر دولت‌ها به این تکنولوژی‌ها دسترسی داشته باشن (که قطعاً دارن) چه کارهایی میشه باهاش کرد که اهداف بیشترشون در تضاد حقوق شهروندی می‌تونه باشه. ولی مسئله‌ی اصلی اینه که دسترسی به تکنولوژی اونقدر راحت هست که نه تنها دولت‌ها، بلکه هر کس دیگه‌ای می‌تونه بهش دسترسی داشته باشه و بر اساس نیازهاش تغییرش بده.

حال این ویدیو رو ببینید:

<div>
<iframe width="1280" height="720" src="https://www.youtube-nocookie.com/embed/9CO6M2HsoIA?rel=0" frameborder="0" allowfullscreen></iframe>
</div>

این ویدیو ساختگی هست، برای کمپین ایجاد قوانین محدودکننده برای سلاح‌های خودمختار [۵]. این ویدیو خیلی باعث ترس و نگرانی من شد. چیزی که توی این ویدیو نشون میدن تکنولوژی عجیب یا دور از دسترسی نیست. شاید یک تیم چند نفره‌ای که برنامه‌نویسی بلد هستن بتونن در مدت چند ماه حرکت هوشمندانه‌ی این پهپاد رو درست بکنن. درست کردن بقیه‌ی قسمت‌هاش هم خیلی زمان نمی‌بره.درسته تخمین‌های من اشتباه هستن، ولی رسیدن به این تکنولوژی نیازی به زمان و هزینه و تخصص (در عمل به اندازه‌ی) بینهایت نداره. با منابع محدودتری هم میشه به این تکنولوژی دست یافت و این خیلی ترسناکه.)
شاید کشورهایی که در اون‌ها جایگاه و منزلت قانون بیشتره، مثل امریکا یا کشورهای اتحادیه‌ی اروپا واقعاً بتونن به قوانین محدود کننده دست پیدا بکنن، ولی نگرانی بزرگ‌تر اینجا شروع میشه. کشورهایی که به اندازه‌ی کافی در چارچوب قوانین نیستن و یا تمامیت‌خواه و سرکوب‌گر هستن، به راحتی می‌تونن از این تکنولوژی‌های برای مقاصد نادرست استفاده بکنن. علاوه بر اون کشورهای تابع قوانین هم خیلی راحت می‌تونن این تکنولوژی‌هاشون رو بر روی ملل دولت‌های ضعیف‌تر امتحان بکنن. بخاطر همینه که پیشرفت تکنولوژی از خیلی جهات خیلی بیشتر باعث ضرر مردمان کشورهای ضعیف از نظر سیاسی و دسترسی به تکنولوژی میشه. این مردمان (ما مردمان) هم از طرف دولت‌های خودشون (خودمون) با ابزار تکنولوژی هوش مصنوعی می‌تونن (می‌تونیم) مورد سرکوب قرار بگیرن (بگیریم) و هم از طرف دولت‌های صادرکننده‌ی دموکراسی. واقعاً در این زمان خیلی سخته شهروند کشوری بود که در اون کشور به اندازه‌ی کافی و لازم به قوانین احترام گذاشته نمیشه.

ولی خب به هر حال نمیشه جلوی پیشرفت تکنولوژی رو گرفت. اتفاقاً جلوی پیشرفتش رو هم گرفتن اشتباهه. در مورد برخورد با هوش مصنوعی چند تا راهکار اصلی وجود داره. بعضی‌ها عقیده دارن که همه‌ی نتایج و دستاوردها باید آزادانه و به سرعت با همه به اشتراک گذاشته بشه تا برتری استراتژیک زیادی بین طرف‌های مختلف وجود نداشته باشه. شاید بشه گفت تا حدودی وضعیت فعلی اهالی دانشگاه و محققان دانشگاهی که در صنعت هستن اینطوری باشه. نظر گروه دیگه‌ای اینه که دستاوردها باید با تامل بیشتری به اشتراک گذاشته بشن. تا وقتی که در مورد درستی و بی‌خطری دستاوردی مطمئن نشدیم نباید اون دستاورد رو با بقیه به اشتراک بذاریم. دسته‌ی آخر هم نظرشون اینه که کلاً باید همه چیز پشت درهای بسته باشه تا همیشه برتری استراتژیک دست ما (که برگزیده‌ترین افراد برای داشتن این اسرار هستیم و صلاح همه‌ی بشر رو بیشتر می‌دونیم) باشه و دست «انسان‌های بد» نیوفته. البته بدیهیه که این رویکرد خیلی شکننده است.

من به اندازه‌ی کافی در مورد این رویکردها فکر نکردم، ولی نظر فعلیم اینه که اشتراک‌گذاری بدون وقفه و آزادانه شاید بهترین روش فعلی باشه. ولی قطعاً این روش پایداری نیست و بهترین گزینه نیست. این روش تضمین نمی‌کنه که همه‌ی طرفین آزادانه دارن همه‌ی نتایج و دستاوردهاشون رو به اشتراک می‌ذارن و اتفاقاً کسایی که با قوانین این بازی، بازی نمی‌کنن شاید بشه گفت که سود بیشتری می‌برن.

از اون طرف به کارگیری روزمره‌ی تکنولوژی‌های مبتنی بر هوش مصنوعی در همه‌ی زمینه‌های زندگی حتماً اثرات منفی مختلفی داره ولی نمیشه جلوی این رو گرفت. به نظر شما چطوری میشه اثرگذاری این تکنولوژی رو مثبت‌تر کرد؟ واقعاً آیا راه‌حلی وجود داره؟



اگر خیلی مثل گذشته تنبلی بر من غلبه نکنه، در آینده بیشتر در مورد ایمنی هوش مصنوعی [۶] خواهم نوشت.

[1] Turing, Alan M. "Computing machinery and intelligence." Mind 59.236 (1950): 433-460.

[2] Artificial General Intelligence

[3] Singularitarians

[4] arxiv.org/

[5] Autonomous Weapons

[6] AI Safety
