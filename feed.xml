<feed xmlns="http://www.w3.org/2005/Atom"><title type="text">The Gradient</title><subtitle type="text">The Gradient</subtitle><id>http://blog.erfan.xyz/</id><updated>2016-11-21T00:19:43+03:30</updated><author><name>عرفان</name><uri>http://blog.erfan.xyz</uri><email>ennry@outlook.com</email></author><generator>Sandra.Snow Atom Generator</generator><link rel="alternate" href="http://blog.erfan.xyz/feed.xml" /><link rel="self" type="text/html" title="The Gradient" href="http://blog.erfan.xyz/feed.xml" /><entry><id>http://blog.erfan.xyz/2016/11/iqa-iclr2017/</id><title type="text">Paper notes for "A Context-aware Attention Network for Interactive Question Answering"</title><summary type="html">&lt;h1&gt;به نام خدا&lt;/h1&gt;

&lt;p&gt;I just read this paper that is submitted to ICRL 2017 and thought that I might write my notes as a post in the blog. It is a quite interesting and useful habit to publish these notes, but I have been a little lazy before. I'll try to publish more from now on.&lt;/p&gt;

&lt;h1&gt;A Context-aware Attention Network for Interactive Question Answering&lt;/h1&gt;

&lt;p&gt;&lt;a href="http://webpages.uncc.edu/~hli38/"&gt;Huayu Li&lt;/a&gt;, Martin Renqiang Min, Yong Ge, Asim Kadav&lt;/p&gt;

&lt;p&gt;Link(s): &lt;a href="https://openreview.net/forum?id=SkyQWDcex"&gt;OpenReview&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;Summary&lt;/h2&gt;

&lt;p&gt;It is an extension of the encoder-decoder framework for the task of question answering, which has two levels of attention when encoding sentences of the story and also when encoding the words of each sentence. Although "attention" term is used throughout the paper, "importance weighting" would better convey the idea of the paper. In addition to this, the other novelty of the paper is introducing a feedback mechanism for when the model doesn't have enough information to generate a correct answer. To test their model's ability to ask question from a user and obtain feedback, they also introduce a new dataset based on bAbI, named "ibAbI".&lt;/p&gt;

&lt;h2&gt;More in depth&lt;/h2&gt;

&lt;p&gt;This architecture consists of three main modules:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Question Module&lt;/li&gt;
&lt;li&gt;Story Module&lt;/li&gt;
&lt;li&gt;Answer Module&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Let's start by first looking at this figure from the paper.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://blog.erfan.xyz/stylesheets/images/iqa-figure2.png" alt="Figure 2 from paper schematically showing the three modules used in the network architecture" /&gt;&lt;/p&gt;

&lt;p&gt;In the problem of textual question answering, we are given a question sentence and a sequence of story sentences. The goal is to find the answer to the question given the story sentences. Each sentence is a sequence of words.&lt;/p&gt;

&lt;h3&gt;Question Module&lt;/h3&gt;

&lt;p&gt;Given a question sentence as a sequence of words, $(\omega^q _ 1,\cdots,\omega _ {N _ q}^q)$, each word is first embedded using an embedding matrix \(\boldsymbol{W} _ \omega\). To achieve an encoding which takes the sequential nature of this sentence into account, a \(GRU _ \omega\) is used. Usually the last hidden state of the recurrent model is used as the encoding of a sequence. However, in this work, they use importance weighting (or "attention") to obtain the encoding of the sequence, using hidden states of the GRU throughout the sequence. To determine the importance of the hidden state at each time step, its similarity with a vector \(\mathbf{v}\) is used. This vector is learned jointly with the model. Although in general it doesn't look like a good idea to use a static vector to assess the importance of each word in a question sentence, however in this case, given mostly short questions, it seems to work. A better approach would be to use techniques like coattention, i.e. to use representation from the input sentences to assess the importance of words in the question sentence. In addition, it would be much better if results without this static attention were also reported, to show how much, if any, is this approach beneficial to the overall system. Anyways, after normalizing the "attention" weights using softmax, weighted some of hidden states is calculated and using a one-layer linear MLP, is projected into "context-level" vector space, thus&lt;/p&gt;

&lt;p&gt;$$ \mathbf{u} = \mathbf{W} _ {ch} \sum _ {j=1}^{N _ q} \gamma _ j \mathbf{g} _ j ^ q + b _ c ^ {(q)} $$&lt;/p&gt;

&lt;p&gt;So we have vector $\mathbf{u}$ as the vector representation of the question sentence.&lt;/p&gt;

&lt;h3&gt;Input Module&lt;/h3&gt;

&lt;h4&gt;&lt;strong&gt;Sentence Encoder&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;"Input module aims at generating a representation for input sentences, including a sentence encoder
and a context encoder". Input module is given a number of sentences each containing $N _ t$ words. Sentence encoder will encode each sentence into a vector representation, and then the context encoder will encode the sequence of sentence embeddings into a sequence of contextual embeddings, embeddings that take context into account. Let's start from the sentence encoder. As usual each word is embedded first using the embedding matrix $\boldsymbol{W} _ \omega$ (embedding matrices are shared in all modules). Then using a GRU, $GRU _ \omega$, these embeddings are transformed into a sequence of hidden states, $(\mathbf{h} ^ t _ 1, \cdots, \mathbf{h} ^ t _ {N _ t}).$ After this, the important step of word-level attention occurs. What is important and one of the main novelties of this work, is that contextual information from previous sentences is used in this step. &lt;/p&gt;

&lt;p&gt;&lt;img src="http://blog.erfan.xyz/stylesheets/images/sentence-enc-iqa.png" alt="A hand-drawn diagram of the sentence encoder" /&gt;&lt;/p&gt;

&lt;p&gt;The diagram above is the missing figure from the paper! Well, just kidding. Figure 2 from paper is quite informative. This is just a supplementary diagram to make things more clear.&lt;/p&gt;

&lt;p&gt;As can be seen in the figure above, after using a GRU's hidden states as preliminary representation of the input sentence words, a context vector from the last input sentence is used to transform hidden state representations to another representation which takes the overall context of previous sentences into account. For this transformation, a two layer MLP is used (Equation 5) to obtain the sequence of "context-injected" representations of sentence $l _ t$, $(\mathbf{e} ^ t _ 1, \cdots, \mathbf{e} ^ t _ {N _ t})$. Afterwards, vector representation of the question, $\mathbf{u}$, is used to obtain importance weighting of the words in the sentence and these weights, after being normalized, are used to get a weighted sum of the representations of words of sentence, $\mathbf{y} _ t$. This vector representation of sentence $l _ t$ not only has word-level attention, but also context from previous sentences have been taken into account.&lt;/p&gt;

&lt;p&gt;A question that comes to mind is why this attention mechanism isn't incorporated inside the GRU itself? Although the current architecture has allowed the model to have shared parameters in GRUs when encoding the question, input sentences, and the feedback sentence, but it would be interesting to see how the model would perform if attention was baked into the GRU, like the Attentional GRU in the DMN+[1] paper.&lt;/p&gt;

&lt;h4&gt;&lt;strong&gt;Context Encoder&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;Context encoder simply uses another GRU, $GRU _ s$, to encode sequence of sentence representations from the sentence encoder into another sequence $(\mathbf{s} _ 1, \cdots, \mathbf{s} _ N)$. This lets the model encode the sequential structure into the representation obtained from the sentence encoder. Afterwards, just like the sentence encoder, inner product with question representation $\mathbf{u}$ is used to weight importance of each representation in the sequence of sentences. These weights are then used to get the input encoding vector $\mathbf{m}$ (Equations 8 and 9).&lt;/p&gt;

&lt;h3&gt;Answer Module&lt;/h3&gt;

&lt;p&gt;As clearly can be seen, this architecture is an extension of attention-less sequence to sequence models. It has the bottleneck vector representation $\mathbf{u} + \mathbf{m}$, which is used to condition the language model in the Answer Module. It doesn't have attention mechanism in the decoder, it only has the attention in the encoder portion of the architecture (similar to many VQA models). Although results are impressive (on the bAbI dataset), it would be interesting to see how this architecture (without the feedback mechanism) would fare against models that incorporate attention in their decoder.&lt;/p&gt;

&lt;p&gt;The answer generation module is a language model that conditioned on the $\mathbf{u} + \mathbf{m}$ generates the answer to the question. However, the interesting part happens after this language model generates the first answer. There two EOS sentinel characters defined in this model, the question mark and the period. In case the generated sequence ends with a period, the model has decided that it has enough information to generate the answer to the question, given the input sentences. However, if the generated sequence ends with a question mark, it means that the model is asking for more feedback to be able to answer the question. After the model generates a question and gets a feedback, uses the representation of the feedback sentence, $\mathbf{f}$, to update its attention over the sequence of sentence embeddings. It is interesting that they use simple uniform importance weighting over the words of the feedback sentence to obtain its vector representation, instead of attention using the question representation, or the supplementary question generated by the model, or even only using the final state of the $GRU _ \omega$ used for processing the feedback sentence. The updated representation which is the sum of the question representation and the updated overall sentences representation is used to generate the final answer, given the feedback to the model. To simplify the model, they "allow the decoder to only generate at most one supplementary question". Although it may be tempting to allow the model to be able to ask more than one supplementary question, however since answer to these supplementary questions only would update the representation of the model of the input sentences, not increase model's overall knowledge, therefore it won't hurt much to limit the model to at most one supplementary question. The ability to increase model's knowledge using the feedback might make model more capable, although with increased complexity.&lt;/p&gt;

&lt;h3&gt;Experiments&lt;/h3&gt;

&lt;p&gt;They report that "training can be treated as a supervised classification problem" and they try "to minimize the cross-entropy error of
the answer sequence and the supplementary question sequence". 
The evaluate their model on the bAbI dataset and a newly proposed ibAbI (interactive bAbI) dataset. They compare their models with DMN+[1], MemN2N[2], and a simple EncDec[3] model. Their model successfully manages to solve 19 out of 20 of the bAbI tasks (Table 4). They also get significantly better results on the ibAbI dataset compared to the other models evaluated. &lt;/p&gt;

&lt;h3&gt;Final words&lt;/h3&gt;

&lt;p&gt;The paper was interesting, although short of some details. They could also compare their models against an additional number of other models. It would also be great if they could provide an open source implementation of the proposed model. I still can't think of a way to implement the Input Module. If you have any suggestions comment below.&lt;/p&gt;

&lt;p&gt;[1] Caiming Xiong, Stephen Merity, and Richard Socher. Dynamic memory networks for visual and textual question answering. In ICML, pp. 2397–2406, 2016.&lt;/p&gt;

&lt;p&gt;[2] Sukhbaatar Sainbayar, Szlam Arthur,Weston Jason, and Fergus Rob. End-to-end memory networks. In NIPS, pp. 2440–2448, 2015.&lt;/p&gt;

&lt;p&gt;[3] Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning phrase representations using RNN encoder-decoder for statistical machine translation. In EMNLP, pp. 1724–1734, 2014.&lt;/p&gt;
</summary><published>2016-11-18T20:30:00Z</published><updated>2016-11-18T20:30:00Z</updated><link rel="alternate" href="http://blog.erfan.xyz/2016/11/iqa-iclr2017/" /><content type="html">&lt;h1&gt;به نام خدا&lt;/h1&gt;

&lt;p&gt;I just read this paper that is submitted to ICRL 2017 and thought that I might write my notes as a post in the blog. It is a quite interesting and useful habit to publish these notes, but I have been a little lazy before. I'll try to publish more from now on.&lt;/p&gt;

&lt;h1&gt;A Context-aware Attention Network for Interactive Question Answering&lt;/h1&gt;

&lt;p&gt;&lt;a href="http://webpages.uncc.edu/~hli38/"&gt;Huayu Li&lt;/a&gt;, Martin Renqiang Min, Yong Ge, Asim Kadav&lt;/p&gt;

&lt;p&gt;Link(s): &lt;a href="https://openreview.net/forum?id=SkyQWDcex"&gt;OpenReview&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;Summary&lt;/h2&gt;

&lt;p&gt;It is an extension of the encoder-decoder framework for the task of question answering, which has two levels of attention when encoding sentences of the story and also when encoding the words of each sentence. Although "attention" term is used throughout the paper, "importance weighting" would better convey the idea of the paper. In addition to this, the other novelty of the paper is introducing a feedback mechanism for when the model doesn't have enough information to generate a correct answer. To test their model's ability to ask question from a user and obtain feedback, they also introduce a new dataset based on bAbI, named "ibAbI".&lt;/p&gt;

&lt;h2&gt;More in depth&lt;/h2&gt;

&lt;p&gt;This architecture consists of three main modules:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Question Module&lt;/li&gt;
&lt;li&gt;Story Module&lt;/li&gt;
&lt;li&gt;Answer Module&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Let's start by first looking at this figure from the paper.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://blog.erfan.xyz/stylesheets/images/iqa-figure2.png" alt="Figure 2 from paper schematically showing the three modules used in the network architecture" /&gt;&lt;/p&gt;

&lt;p&gt;In the problem of textual question answering, we are given a question sentence and a sequence of story sentences. The goal is to find the answer to the question given the story sentences. Each sentence is a sequence of words.&lt;/p&gt;

&lt;h3&gt;Question Module&lt;/h3&gt;

&lt;p&gt;Given a question sentence as a sequence of words, $(\omega^q _ 1,\cdots,\omega _ {N _ q}^q)$, each word is first embedded using an embedding matrix \(\boldsymbol{W} _ \omega\). To achieve an encoding which takes the sequential nature of this sentence into account, a \(GRU _ \omega\) is used. Usually the last hidden state of the recurrent model is used as the encoding of a sequence. However, in this work, they use importance weighting (or "attention") to obtain the encoding of the sequence, using hidden states of the GRU throughout the sequence. To determine the importance of the hidden state at each time step, its similarity with a vector \(\mathbf{v}\) is used. This vector is learned jointly with the model. Although in general it doesn't look like a good idea to use a static vector to assess the importance of each word in a question sentence, however in this case, given mostly short questions, it seems to work. A better approach would be to use techniques like coattention, i.e. to use representation from the input sentences to assess the importance of words in the question sentence. In addition, it would be much better if results without this static attention were also reported, to show how much, if any, is this approach beneficial to the overall system. Anyways, after normalizing the "attention" weights using softmax, weighted some of hidden states is calculated and using a one-layer linear MLP, is projected into "context-level" vector space, thus&lt;/p&gt;

&lt;p&gt;$$ \mathbf{u} = \mathbf{W} _ {ch} \sum _ {j=1}^{N _ q} \gamma _ j \mathbf{g} _ j ^ q + b _ c ^ {(q)} $$&lt;/p&gt;

&lt;p&gt;So we have vector $\mathbf{u}$ as the vector representation of the question sentence.&lt;/p&gt;

&lt;h3&gt;Input Module&lt;/h3&gt;

&lt;h4&gt;&lt;strong&gt;Sentence Encoder&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;"Input module aims at generating a representation for input sentences, including a sentence encoder
and a context encoder". Input module is given a number of sentences each containing $N _ t$ words. Sentence encoder will encode each sentence into a vector representation, and then the context encoder will encode the sequence of sentence embeddings into a sequence of contextual embeddings, embeddings that take context into account. Let's start from the sentence encoder. As usual each word is embedded first using the embedding matrix $\boldsymbol{W} _ \omega$ (embedding matrices are shared in all modules). Then using a GRU, $GRU _ \omega$, these embeddings are transformed into a sequence of hidden states, $(\mathbf{h} ^ t _ 1, \cdots, \mathbf{h} ^ t _ {N _ t}).$ After this, the important step of word-level attention occurs. What is important and one of the main novelties of this work, is that contextual information from previous sentences is used in this step. &lt;/p&gt;

&lt;p&gt;&lt;img src="http://blog.erfan.xyz/stylesheets/images/sentence-enc-iqa.png" alt="A hand-drawn diagram of the sentence encoder" /&gt;&lt;/p&gt;

&lt;p&gt;The diagram above is the missing figure from the paper! Well, just kidding. Figure 2 from paper is quite informative. This is just a supplementary diagram to make things more clear.&lt;/p&gt;

&lt;p&gt;As can be seen in the figure above, after using a GRU's hidden states as preliminary representation of the input sentence words, a context vector from the last input sentence is used to transform hidden state representations to another representation which takes the overall context of previous sentences into account. For this transformation, a two layer MLP is used (Equation 5) to obtain the sequence of "context-injected" representations of sentence $l _ t$, $(\mathbf{e} ^ t _ 1, \cdots, \mathbf{e} ^ t _ {N _ t})$. Afterwards, vector representation of the question, $\mathbf{u}$, is used to obtain importance weighting of the words in the sentence and these weights, after being normalized, are used to get a weighted sum of the representations of words of sentence, $\mathbf{y} _ t$. This vector representation of sentence $l _ t$ not only has word-level attention, but also context from previous sentences have been taken into account.&lt;/p&gt;

&lt;p&gt;A question that comes to mind is why this attention mechanism isn't incorporated inside the GRU itself? Although the current architecture has allowed the model to have shared parameters in GRUs when encoding the question, input sentences, and the feedback sentence, but it would be interesting to see how the model would perform if attention was baked into the GRU, like the Attentional GRU in the DMN+[1] paper.&lt;/p&gt;

&lt;h4&gt;&lt;strong&gt;Context Encoder&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;Context encoder simply uses another GRU, $GRU _ s$, to encode sequence of sentence representations from the sentence encoder into another sequence $(\mathbf{s} _ 1, \cdots, \mathbf{s} _ N)$. This lets the model encode the sequential structure into the representation obtained from the sentence encoder. Afterwards, just like the sentence encoder, inner product with question representation $\mathbf{u}$ is used to weight importance of each representation in the sequence of sentences. These weights are then used to get the input encoding vector $\mathbf{m}$ (Equations 8 and 9).&lt;/p&gt;

&lt;h3&gt;Answer Module&lt;/h3&gt;

&lt;p&gt;As clearly can be seen, this architecture is an extension of attention-less sequence to sequence models. It has the bottleneck vector representation $\mathbf{u} + \mathbf{m}$, which is used to condition the language model in the Answer Module. It doesn't have attention mechanism in the decoder, it only has the attention in the encoder portion of the architecture (similar to many VQA models). Although results are impressive (on the bAbI dataset), it would be interesting to see how this architecture (without the feedback mechanism) would fare against models that incorporate attention in their decoder.&lt;/p&gt;

&lt;p&gt;The answer generation module is a language model that conditioned on the $\mathbf{u} + \mathbf{m}$ generates the answer to the question. However, the interesting part happens after this language model generates the first answer. There two EOS sentinel characters defined in this model, the question mark and the period. In case the generated sequence ends with a period, the model has decided that it has enough information to generate the answer to the question, given the input sentences. However, if the generated sequence ends with a question mark, it means that the model is asking for more feedback to be able to answer the question. After the model generates a question and gets a feedback, uses the representation of the feedback sentence, $\mathbf{f}$, to update its attention over the sequence of sentence embeddings. It is interesting that they use simple uniform importance weighting over the words of the feedback sentence to obtain its vector representation, instead of attention using the question representation, or the supplementary question generated by the model, or even only using the final state of the $GRU _ \omega$ used for processing the feedback sentence. The updated representation which is the sum of the question representation and the updated overall sentences representation is used to generate the final answer, given the feedback to the model. To simplify the model, they "allow the decoder to only generate at most one supplementary question". Although it may be tempting to allow the model to be able to ask more than one supplementary question, however since answer to these supplementary questions only would update the representation of the model of the input sentences, not increase model's overall knowledge, therefore it won't hurt much to limit the model to at most one supplementary question. The ability to increase model's knowledge using the feedback might make model more capable, although with increased complexity.&lt;/p&gt;

&lt;h3&gt;Experiments&lt;/h3&gt;

&lt;p&gt;They report that "training can be treated as a supervised classification problem" and they try "to minimize the cross-entropy error of
the answer sequence and the supplementary question sequence". 
The evaluate their model on the bAbI dataset and a newly proposed ibAbI (interactive bAbI) dataset. They compare their models with DMN+[1], MemN2N[2], and a simple EncDec[3] model. Their model successfully manages to solve 19 out of 20 of the bAbI tasks (Table 4). They also get significantly better results on the ibAbI dataset compared to the other models evaluated. &lt;/p&gt;

&lt;h3&gt;Final words&lt;/h3&gt;

&lt;p&gt;The paper was interesting, although short of some details. They could also compare their models against an additional number of other models. It would also be great if they could provide an open source implementation of the proposed model. I still can't think of a way to implement the Input Module. If you have any suggestions comment below.&lt;/p&gt;

&lt;p&gt;[1] Caiming Xiong, Stephen Merity, and Richard Socher. Dynamic memory networks for visual and textual question answering. In ICML, pp. 2397–2406, 2016.&lt;/p&gt;

&lt;p&gt;[2] Sukhbaatar Sainbayar, Szlam Arthur,Weston Jason, and Fergus Rob. End-to-end memory networks. In NIPS, pp. 2440–2448, 2015.&lt;/p&gt;

&lt;p&gt;[3] Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning phrase representations using RNN encoder-decoder for statistical machine translation. In EMNLP, pp. 1724–1734, 2014.&lt;/p&gt;
</content></entry><entry><id>http://blog.erfan.xyz/2016/01/office-365-student/</id><title type="text">آفیس رایگان برای دانشجویان</title><summary type="html">&lt;h1&gt;به نام خدا&lt;/h1&gt;

&lt;p&gt;چون دانشجویان در سراسر دنیا قشر فقیری هست(!)، بخاطر همین خیلی از شرکت‌های نرم‌افزاری سعی می‌کنن بعضی از سرویس‌ها و نرم‌افزارهاشون رو با قیمت پایین یا به صورت رایگان به دانشجویان ارائه بکنن. نمونه‌اش مثلاً گیت‌هابه که پنج تا repository خصوصی به هر دانشجو میده، یا مثلاً شرکت Autodesk نرم‌افزار AutoCAD یا یه تعداد دیگه‌ای از نرم‌افزارهاش رو به صورت رایگان میده، شرکت Jetbrains اجازه‌ی استفاده از IDEهاش و البته Resharper رو به صورت رایگان میده و کلی چیز دیگه که اگر بگردید حتماً پیدا می‌کنید.&lt;/p&gt;

&lt;p&gt;یکی دیگه از شرکت‌هایی که از قدیم کلی خدمات رایگان به دانشجوها میده شرکت Microsoft هست. این شرکت تحت برنامه‌ی &lt;a href="https://dreamspark.com"&gt;Dreamspark&lt;/a&gt; یه سری از خدمات رو از سال‌ها قبل ارائه میداد، خدماتی مثل Windows Server، SQL Server، Microsoft R Server و البته خدماتی با همکاری شرکت‌های دیگه مثل Github و Xamarin و یه مدت استفاده از آموزش‌های سایت Pluralsight. قدیم‌ها هم که ویژوال استودیو کلاً نسخه‌ی رایگان نداشت، نسخه‌ی Professional ویژوال استودیو رو هم میشد از طریق این برنامه گرفت. ولی الان که نسخه‌ی رایگان Community به نسخه‌های ویژوال استودیو اضافه شده نیاز به این خدمت کم شده. راستی اخیراً هم اکانت رایگان Azure به کاتالوگ خدمات Dreamspark اضافه شده که البته فعلاً نمیشه از ایران فعالش کرد. باید صبر کرد ببینیم این مشکل رو حل می‌کنن یا نه.&lt;/p&gt;

&lt;p&gt;قبلاً از طریق برنامه‌ی Dreamspark میشد تخفیف برای خرید subscription آفیس 365 گرفت، ولی این رو برداشتن. &lt;/p&gt;

&lt;p&gt;به جاش الان آفیس 365 به صورت رایگان به دانشجوها داده میشه!! :)&lt;/p&gt;

&lt;p&gt;شاید یک سال قبل (یا کمتر یا بیشتر، دقیق یادم نیست) بود که اعلام شد مایکروسافت به دانشجوها subscription آفیس 365 رو به صورت رایگان ارائه خواهد داد. برای اینکار هم نیاز به این دارید که آدرس ایمیل از طرف دانشگاه با دامنه‌ی .edu داشته باشید. &lt;/p&gt;

&lt;p&gt;مشکل این بود که این امکان برای ایران نبود، یعنی با ایمیل دانشگاه‌های ایرانی نمیشد این کار رو کرد. ولی امروز به صورت اتفاقی دوباره سعی کردم این کار رو بکنم و موفق شدم. یعنی احتمالاً مدتی هست که این امکان فراهم شده و بالاخره از اینجا با ایمیل دانشگاه‌های ایرانی هم میشه آفیس 365 رو گرفت. برای اینکار کافیه به ا&lt;a href="https://products.office.com/en-us/student/office-in-education"&gt;ین آدرس&lt;/a&gt;  برید و با وارد کردن ایمیل دانشگاهی‌تون حساب آفیس 365 رو دریافت کنید. با این کار یک ترابایت فضای رایگان روی OneDrive می‌گیرید. بعد می‌تونید نرم‌افزار آفیس رو بدون نیاز به کرک کردن استفاده کنید (البته من رو نسخه‌ی Office Standard امتحان کردم، چون این برنامه شامل نرم‌افزارهای Word، PowerPoint، OneNote و Excel میشه) نسخه‌های دیگه شامل نرم‌افزارهای دیگه‌ای هستن که توی این توافقنامه نیستن. در ضمن با این کار میشه آفیس رو روی 5 تا از کامپیوترهاتون استفاده کنید (PC و Mac) (توجه کنید روی کامپیوترهاتون، نه روی کامپیوتر خودتون و کسای دیگه، این License فقط به یک شخص حقیقی داده میشه). بعد روی موبایل و تبلت‌تون هم می‌تونید ازش استفاده کنید (روی همه‌ی سیستم‌عامل‌ها).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;سلب مسئولیت&lt;/strong&gt; (فارسی همون Disclaimer): من این کارها رو با ایمیل دانشگاهی که توش مشغول تحصیل هستم (دانشگاه شریف) امتحان کردم، در مورد دانشگا‌ه‌های دیگه‌ی ایران اطلاعی ندارم.&lt;/p&gt;
</summary><published>2016-01-19T20:30:00Z</published><updated>2016-01-19T20:30:00Z</updated><link rel="alternate" href="http://blog.erfan.xyz/2016/01/office-365-student/" /><content type="html">&lt;h1&gt;به نام خدا&lt;/h1&gt;

&lt;p&gt;چون دانشجویان در سراسر دنیا قشر فقیری هست(!)، بخاطر همین خیلی از شرکت‌های نرم‌افزاری سعی می‌کنن بعضی از سرویس‌ها و نرم‌افزارهاشون رو با قیمت پایین یا به صورت رایگان به دانشجویان ارائه بکنن. نمونه‌اش مثلاً گیت‌هابه که پنج تا repository خصوصی به هر دانشجو میده، یا مثلاً شرکت Autodesk نرم‌افزار AutoCAD یا یه تعداد دیگه‌ای از نرم‌افزارهاش رو به صورت رایگان میده، شرکت Jetbrains اجازه‌ی استفاده از IDEهاش و البته Resharper رو به صورت رایگان میده و کلی چیز دیگه که اگر بگردید حتماً پیدا می‌کنید.&lt;/p&gt;

&lt;p&gt;یکی دیگه از شرکت‌هایی که از قدیم کلی خدمات رایگان به دانشجوها میده شرکت Microsoft هست. این شرکت تحت برنامه‌ی &lt;a href="https://dreamspark.com"&gt;Dreamspark&lt;/a&gt; یه سری از خدمات رو از سال‌ها قبل ارائه میداد، خدماتی مثل Windows Server، SQL Server، Microsoft R Server و البته خدماتی با همکاری شرکت‌های دیگه مثل Github و Xamarin و یه مدت استفاده از آموزش‌های سایت Pluralsight. قدیم‌ها هم که ویژوال استودیو کلاً نسخه‌ی رایگان نداشت، نسخه‌ی Professional ویژوال استودیو رو هم میشد از طریق این برنامه گرفت. ولی الان که نسخه‌ی رایگان Community به نسخه‌های ویژوال استودیو اضافه شده نیاز به این خدمت کم شده. راستی اخیراً هم اکانت رایگان Azure به کاتالوگ خدمات Dreamspark اضافه شده که البته فعلاً نمیشه از ایران فعالش کرد. باید صبر کرد ببینیم این مشکل رو حل می‌کنن یا نه.&lt;/p&gt;

&lt;p&gt;قبلاً از طریق برنامه‌ی Dreamspark میشد تخفیف برای خرید subscription آفیس 365 گرفت، ولی این رو برداشتن. &lt;/p&gt;

&lt;p&gt;به جاش الان آفیس 365 به صورت رایگان به دانشجوها داده میشه!! :)&lt;/p&gt;

&lt;p&gt;شاید یک سال قبل (یا کمتر یا بیشتر، دقیق یادم نیست) بود که اعلام شد مایکروسافت به دانشجوها subscription آفیس 365 رو به صورت رایگان ارائه خواهد داد. برای اینکار هم نیاز به این دارید که آدرس ایمیل از طرف دانشگاه با دامنه‌ی .edu داشته باشید. &lt;/p&gt;

&lt;p&gt;مشکل این بود که این امکان برای ایران نبود، یعنی با ایمیل دانشگاه‌های ایرانی نمیشد این کار رو کرد. ولی امروز به صورت اتفاقی دوباره سعی کردم این کار رو بکنم و موفق شدم. یعنی احتمالاً مدتی هست که این امکان فراهم شده و بالاخره از اینجا با ایمیل دانشگاه‌های ایرانی هم میشه آفیس 365 رو گرفت. برای اینکار کافیه به ا&lt;a href="https://products.office.com/en-us/student/office-in-education"&gt;ین آدرس&lt;/a&gt;  برید و با وارد کردن ایمیل دانشگاهی‌تون حساب آفیس 365 رو دریافت کنید. با این کار یک ترابایت فضای رایگان روی OneDrive می‌گیرید. بعد می‌تونید نرم‌افزار آفیس رو بدون نیاز به کرک کردن استفاده کنید (البته من رو نسخه‌ی Office Standard امتحان کردم، چون این برنامه شامل نرم‌افزارهای Word، PowerPoint، OneNote و Excel میشه) نسخه‌های دیگه شامل نرم‌افزارهای دیگه‌ای هستن که توی این توافقنامه نیستن. در ضمن با این کار میشه آفیس رو روی 5 تا از کامپیوترهاتون استفاده کنید (PC و Mac) (توجه کنید روی کامپیوترهاتون، نه روی کامپیوتر خودتون و کسای دیگه، این License فقط به یک شخص حقیقی داده میشه). بعد روی موبایل و تبلت‌تون هم می‌تونید ازش استفاده کنید (روی همه‌ی سیستم‌عامل‌ها).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;سلب مسئولیت&lt;/strong&gt; (فارسی همون Disclaimer): من این کارها رو با ایمیل دانشگاهی که توش مشغول تحصیل هستم (دانشگاه شریف) امتحان کردم، در مورد دانشگا‌ه‌های دیگه‌ی ایران اطلاعی ندارم.&lt;/p&gt;
</content></entry><entry><id>http://blog.erfan.xyz/2015/09/new-address/</id><title type="text">آدرس جدید!</title><summary type="html">&lt;h1&gt;به نام خدا&lt;/h1&gt;

&lt;p&gt;راستی آدرس اینجا هم تغییر کرده. یعنی علاوه بر اینکه میشه با آدرس قبلی &lt;a href="http://erfannoury.github.io"&gt;http://erfannoury.github.io&lt;/a&gt; به اینجا دسترسی پیدا کرد، حالا آدرس &lt;a href="http://blog.erfan.xyz"&gt;http://blog.erfan.xyz&lt;/a&gt; هم اضافه شده. با این آدرس هم میشه به بلاگ دسترسی پیدا کرد. &lt;/p&gt;
</summary><published>2015-09-04T19:30:00Z</published><updated>2015-09-04T19:30:00Z</updated><link rel="alternate" href="http://blog.erfan.xyz/2015/09/new-address/" /><content type="html">&lt;h1&gt;به نام خدا&lt;/h1&gt;

&lt;p&gt;راستی آدرس اینجا هم تغییر کرده. یعنی علاوه بر اینکه میشه با آدرس قبلی &lt;a href="http://erfannoury.github.io"&gt;http://erfannoury.github.io&lt;/a&gt; به اینجا دسترسی پیدا کرد، حالا آدرس &lt;a href="http://blog.erfan.xyz"&gt;http://blog.erfan.xyz&lt;/a&gt; هم اضافه شده. با این آدرس هم میشه به بلاگ دسترسی پیدا کرد. &lt;/p&gt;
</content></entry><entry><id>http://blog.erfan.xyz/2015/09/installing-theano-2/</id><title type="text">نصب کتابخانه‌ی Theano در ویندوز (به‌روزرسانی)</title><summary type="html">&lt;h1&gt;به نام خدا&lt;/h1&gt;

&lt;p&gt;بعد از پست قبلی در مورد نصب Theano بر روی ویندوز، تغییرات زیادی در این زمینه و کتابخانه‌های یادگیری عمیق و وضعیت نصب اونها روی ویندوز ایجاد شده. این پست به نوعی به‌روزرسانی بر روی موضوع نصب این کتابخانه‌ی پایه‌ای و بعد معرفی یک کتابخانه‌ی جدیده.&lt;/p&gt;

&lt;h2&gt;نکات جدید برای نصب Theano&lt;/h2&gt;

&lt;p&gt;چند روز پیش می‌خواستم این کتابخانه رو روی یک کامپیوتر جدید نصب کنم.
اولین کاری که کردم دانلود کردن و نصب Anaconda Python، CUDA 7.0 و البته Visual Studio 2013 بود. بخاطر اینکه هنوز CUDA از Visual Studio 2015 پشتیبانی نمی‌کنه، سراغ نسخه‌ی جدیدش نرفتم.
بعد از اینکه اینا رو نصب کردم (اول ویژوال استودیو، بعد پایتون، در نهایت کودا) رفتم سراغ نصب gcc. درسته که برای کامپایل‌کردن قسمت اصلی کد Theano از کامپایلر مایکروسافت استفاده میشه، ولی بعضی از تیکه‌های کد نیاز به gcc دارن.
برای اینکار &lt;a href="http://tdm-gcc.tdragon.net/"&gt;TDM GCC&lt;/a&gt; رو دانلود و نصب کردم. این نسخه از بقیه زودتر آپدیت میشه و چیز اضافی‌ای هم نصب نمی‌کنه.
بعد از اینکه همه‌ی اینها رو نصب کردم و مطمئن شدم که همه‌ی چیزهای لازم در مسیر سیستم قرار گرفتن رفتم سراغ نصب Theano.&lt;/p&gt;

&lt;p&gt;اولین مشکلی که خوردم این بود که وقتی از gcc می‌خواست استفاده کنه خطای عدم وجود فایل‌های لازم برای پایتون رو میداد. رفتم خوب مسیر پایتون (پوشه‌ی libs) رو بررسی کردم. دیدم که همه چیز درسته.
بعد از کمی جستجو، فهمیدم که gcc نیاز به فایل‌های کتابخانه‌ای با فرمت &lt;code&gt;libpython27.a&lt;/code&gt; داره، نه &lt;code&gt;python27.lib&lt;/code&gt;. بنابراین باید اول این فایل رو پیدا (یا درست) می‌کردم و بعد در همون پوشه قرار میدادم. بعد از اینکار یکی از مشکلات کامپایل حل شد. 
برای حل مشکل به &lt;a href="https://github.com/Theano/Theano/issues/2867"&gt;این لینک&lt;/a&gt; یه نگاهی بندازید.&lt;/p&gt;

&lt;p&gt;مشکل دیگه یه مشکل خیلی عجیب بود. اینکه &lt;code&gt;C:\Windows\System32&lt;/code&gt; تو مسیرهای سیستمی نبود. خیلی عجیب بود این موضوع برام و باعث ایجاد کلی مشکل و گرفتن کلی وقت شد. ولی بعد از اضافه کردن مسیر، کتابخانه به صورت کامل کامپایل شد.&lt;/p&gt;

&lt;p&gt;بعد از این، نوبت درست کردن فایل تنظیمات کتابخانه، یعنی &lt;code&gt;.theanorc&lt;/code&gt; بود. این رو هم در مسیر کاربری قرار دادم و بعدش رفتم سراغ اجرای کتابخانه که بدون مشکل اجرا شد. اینجا به عنوان مرجع، محتوای فایل تنظیمات Theano رو میذارم.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[blas]
ldflags = 
[nvcc]
flags=-LC:\Anaconda\libs
compiler_bindir=C:\Program Files (x86)\Microsoft Visual Studio 12.0\VC\bin
optimizer_including=dnn
fastmath = True
[global]
device = gpu
floatX = float32
[cuda]
root=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;البته اگر خوب ببینید قسمت blas خالیه. برای اون قسمت هم کتابخانه‌ی OpenBLAS رو دانلود کردم و مسیر اون کتابخانه و همچنین اسم فایل کتابخانه‌ی OpenBLAS رو به عنوان ورودی دادم. &lt;/p&gt;

&lt;p&gt;بعد از این مراحل فکر نمی‌کنم مشکلی در نصب Theano پیش بیاد.&lt;/p&gt;

&lt;p&gt;اون &lt;strong&gt;dnn&lt;/strong&gt; هم که نوشتم همون cuDNN هست که انویدیا عرضه کرده تا محاسبات مرتبط با یادگیری عمیق سریعتر بشه. نصب اون هم راحته. بعد از اینکه فایل‌هاش رو دانلود کردید، تو پوشه‌های مرتبط توی محل نصب CUDA قرارشون بدید و اینجا هم اون خط رو به فایل تنظیمات اضافه کنید. cuDNN 2 روی ویندوز بدون مشکل کار می‌کنه، ولی cuDNN 3 رو هنوز امتحان نکردم.&lt;/p&gt;

&lt;h2&gt;کتابخانه‌ی &lt;a href="https://github.com/fchollet/keras"&gt;Keras&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;کتابخانه‌ی یادگیری عمیق Keras یکی از اون کتابخانه‌های یادگیری عمیقه که به نظر میاد آینده‌ی بسیار درخشانی داشته باشه. این کتابخانه روی Theano ساخته شده، ولی API اون از Torch7 الهام گرفته شده و خیلی خوش‌دسته. برخلاف پیچیدگی‌های بالای کار با Theano، کد مربوط به این کتابخانه خیلی خوانا است و به راحتی می‌تونید توش به طراحی مدل و آموزش و تحلیل مدل بپردازید. واقعاً بین همه‌ی کتابخانه‌های یادگیری عمیقی که بررسی کردم (برای پایتون البته)، این بهترین گزینه برای شروع کاره. آموزش‌ها و راهنمایی‌های بسیار خوبی هم تو &lt;a href="http://keras.io/"&gt;این آدرس&lt;/a&gt; گذاشتن. حتماً اگر تصمیم دارید کار روی یادگیری عمیق رو بدون مشکلات زیاد شروع کنید نگاهی به این کتابخانه بندازید.&lt;/p&gt;

&lt;p&gt;در کل بخاطر اینکه افراد و شرکت‌های زیادی پشت کتابخانه‌های Caffe و Torch7 بودن بقیه‌ی کتابخانه‌ها تقریباً عقب مونده بودن. ولی اخیراً احساس می‌کنم که کتابخانه‌های مبتنی بر Theano دارن جایگاه خودشون رو قوی‌تر می‌کنن. خیلی از مقالات اخیر با این کتابخانه‌های پیاده‌سازی شدن و همچنین پیاده‌سازی مقالات زیادی توسط افراد ثالث برای این کتابخانه‌ها انجام می‌گیره. &lt;/p&gt;

&lt;p&gt;هر چقدر گزینه‌ها برای کار کردن زیاد باشن، بهتره. امیدوارم که روز به روز کتابخانه‌ها پیشرفته‌تر و البته ورود به اون‌ها ساده‌تر بشه.&lt;/p&gt;

&lt;p&gt;فکر می‌کنم در روزهای آتی پست‌های متعددی داشته باشم.&lt;/p&gt;
</summary><published>2015-09-03T19:30:00Z</published><updated>2015-09-03T19:30:00Z</updated><link rel="alternate" href="http://blog.erfan.xyz/2015/09/installing-theano-2/" /><content type="html">&lt;h1&gt;به نام خدا&lt;/h1&gt;

&lt;p&gt;بعد از پست قبلی در مورد نصب Theano بر روی ویندوز، تغییرات زیادی در این زمینه و کتابخانه‌های یادگیری عمیق و وضعیت نصب اونها روی ویندوز ایجاد شده. این پست به نوعی به‌روزرسانی بر روی موضوع نصب این کتابخانه‌ی پایه‌ای و بعد معرفی یک کتابخانه‌ی جدیده.&lt;/p&gt;

&lt;h2&gt;نکات جدید برای نصب Theano&lt;/h2&gt;

&lt;p&gt;چند روز پیش می‌خواستم این کتابخانه رو روی یک کامپیوتر جدید نصب کنم.
اولین کاری که کردم دانلود کردن و نصب Anaconda Python، CUDA 7.0 و البته Visual Studio 2013 بود. بخاطر اینکه هنوز CUDA از Visual Studio 2015 پشتیبانی نمی‌کنه، سراغ نسخه‌ی جدیدش نرفتم.
بعد از اینکه اینا رو نصب کردم (اول ویژوال استودیو، بعد پایتون، در نهایت کودا) رفتم سراغ نصب gcc. درسته که برای کامپایل‌کردن قسمت اصلی کد Theano از کامپایلر مایکروسافت استفاده میشه، ولی بعضی از تیکه‌های کد نیاز به gcc دارن.
برای اینکار &lt;a href="http://tdm-gcc.tdragon.net/"&gt;TDM GCC&lt;/a&gt; رو دانلود و نصب کردم. این نسخه از بقیه زودتر آپدیت میشه و چیز اضافی‌ای هم نصب نمی‌کنه.
بعد از اینکه همه‌ی اینها رو نصب کردم و مطمئن شدم که همه‌ی چیزهای لازم در مسیر سیستم قرار گرفتن رفتم سراغ نصب Theano.&lt;/p&gt;

&lt;p&gt;اولین مشکلی که خوردم این بود که وقتی از gcc می‌خواست استفاده کنه خطای عدم وجود فایل‌های لازم برای پایتون رو میداد. رفتم خوب مسیر پایتون (پوشه‌ی libs) رو بررسی کردم. دیدم که همه چیز درسته.
بعد از کمی جستجو، فهمیدم که gcc نیاز به فایل‌های کتابخانه‌ای با فرمت &lt;code&gt;libpython27.a&lt;/code&gt; داره، نه &lt;code&gt;python27.lib&lt;/code&gt;. بنابراین باید اول این فایل رو پیدا (یا درست) می‌کردم و بعد در همون پوشه قرار میدادم. بعد از اینکار یکی از مشکلات کامپایل حل شد. 
برای حل مشکل به &lt;a href="https://github.com/Theano/Theano/issues/2867"&gt;این لینک&lt;/a&gt; یه نگاهی بندازید.&lt;/p&gt;

&lt;p&gt;مشکل دیگه یه مشکل خیلی عجیب بود. اینکه &lt;code&gt;C:\Windows\System32&lt;/code&gt; تو مسیرهای سیستمی نبود. خیلی عجیب بود این موضوع برام و باعث ایجاد کلی مشکل و گرفتن کلی وقت شد. ولی بعد از اضافه کردن مسیر، کتابخانه به صورت کامل کامپایل شد.&lt;/p&gt;

&lt;p&gt;بعد از این، نوبت درست کردن فایل تنظیمات کتابخانه، یعنی &lt;code&gt;.theanorc&lt;/code&gt; بود. این رو هم در مسیر کاربری قرار دادم و بعدش رفتم سراغ اجرای کتابخانه که بدون مشکل اجرا شد. اینجا به عنوان مرجع، محتوای فایل تنظیمات Theano رو میذارم.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[blas]
ldflags = 
[nvcc]
flags=-LC:\Anaconda\libs
compiler_bindir=C:\Program Files (x86)\Microsoft Visual Studio 12.0\VC\bin
optimizer_including=dnn
fastmath = True
[global]
device = gpu
floatX = float32
[cuda]
root=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;البته اگر خوب ببینید قسمت blas خالیه. برای اون قسمت هم کتابخانه‌ی OpenBLAS رو دانلود کردم و مسیر اون کتابخانه و همچنین اسم فایل کتابخانه‌ی OpenBLAS رو به عنوان ورودی دادم. &lt;/p&gt;

&lt;p&gt;بعد از این مراحل فکر نمی‌کنم مشکلی در نصب Theano پیش بیاد.&lt;/p&gt;

&lt;p&gt;اون &lt;strong&gt;dnn&lt;/strong&gt; هم که نوشتم همون cuDNN هست که انویدیا عرضه کرده تا محاسبات مرتبط با یادگیری عمیق سریعتر بشه. نصب اون هم راحته. بعد از اینکه فایل‌هاش رو دانلود کردید، تو پوشه‌های مرتبط توی محل نصب CUDA قرارشون بدید و اینجا هم اون خط رو به فایل تنظیمات اضافه کنید. cuDNN 2 روی ویندوز بدون مشکل کار می‌کنه، ولی cuDNN 3 رو هنوز امتحان نکردم.&lt;/p&gt;

&lt;h2&gt;کتابخانه‌ی &lt;a href="https://github.com/fchollet/keras"&gt;Keras&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;کتابخانه‌ی یادگیری عمیق Keras یکی از اون کتابخانه‌های یادگیری عمیقه که به نظر میاد آینده‌ی بسیار درخشانی داشته باشه. این کتابخانه روی Theano ساخته شده، ولی API اون از Torch7 الهام گرفته شده و خیلی خوش‌دسته. برخلاف پیچیدگی‌های بالای کار با Theano، کد مربوط به این کتابخانه خیلی خوانا است و به راحتی می‌تونید توش به طراحی مدل و آموزش و تحلیل مدل بپردازید. واقعاً بین همه‌ی کتابخانه‌های یادگیری عمیقی که بررسی کردم (برای پایتون البته)، این بهترین گزینه برای شروع کاره. آموزش‌ها و راهنمایی‌های بسیار خوبی هم تو &lt;a href="http://keras.io/"&gt;این آدرس&lt;/a&gt; گذاشتن. حتماً اگر تصمیم دارید کار روی یادگیری عمیق رو بدون مشکلات زیاد شروع کنید نگاهی به این کتابخانه بندازید.&lt;/p&gt;

&lt;p&gt;در کل بخاطر اینکه افراد و شرکت‌های زیادی پشت کتابخانه‌های Caffe و Torch7 بودن بقیه‌ی کتابخانه‌ها تقریباً عقب مونده بودن. ولی اخیراً احساس می‌کنم که کتابخانه‌های مبتنی بر Theano دارن جایگاه خودشون رو قوی‌تر می‌کنن. خیلی از مقالات اخیر با این کتابخانه‌های پیاده‌سازی شدن و همچنین پیاده‌سازی مقالات زیادی توسط افراد ثالث برای این کتابخانه‌ها انجام می‌گیره. &lt;/p&gt;

&lt;p&gt;هر چقدر گزینه‌ها برای کار کردن زیاد باشن، بهتره. امیدوارم که روز به روز کتابخانه‌ها پیشرفته‌تر و البته ورود به اون‌ها ساده‌تر بشه.&lt;/p&gt;

&lt;p&gt;فکر می‌کنم در روزهای آتی پست‌های متعددی داشته باشم.&lt;/p&gt;
</content></entry><entry><id>http://blog.erfan.xyz/2015/03/code-org/</id><title type="text">Code.org</title><summary type="html">&lt;h1&gt;به نام خدا&lt;/h1&gt;

&lt;p&gt;شاید اسم برنامه‌ی «ساعتی با کد» یا "Hour of Code" رو شنیده باشید. هدف این برنامه اینه که در طی یک ساعت، تجربه‌ی ایجاد برنامه رو به افراد مختلف ارائه بکنه.&lt;br /&gt;
سایت &lt;a href="http://code.org"&gt;Code.org&lt;/a&gt; که موسس آن &lt;a href="http://code.org/about/leadership/hadi_partovi"&gt;هادی پرتوی&lt;/a&gt; هست، مجری این برنامه در جهان هست. در این سایت افراد می‌تونن در قالب کاراکترهای مشهوری مانند پرنده‌های بازی Angry Birds یا کاراکترهای انیمیشن Frozen تکه‌کدهایی بنویسن و تجربه‌ی برنامه‌نویسی رو داشته باشن. دوره‌ی اول کدنویسی در این سایت که حداکثر شاید یک ساعت طول بکشه یک برنامه‌ی مفرح و شاد هست که
فرد در طی اون در قالب یک محیط بازی، حرکت کاراکتر رو با استفاده از بلوک‌های اجرایی به عنوان تکه‌های کد، ایجاد می‌کنن.
در این محیط فرد با استفاده از برنامه‌نویسی بلوکی، به جای نوشتن کد به صورت متن، با استفاده از کدهایی منطق بازی رو پیاده‌سازی می‌کنه. در طی این یک ساعت مفاهیمی مثل خط‌به‌خط اجرا شدن کد، تکرار در کد (loop) و همچنین شرط در اجرای کد آموزش داده میشن. بدلیل سادگی محیط، تموم‌کردن ساعتی با کد حتی برای بچه‌ها هم ممکنه و فکر می‌کنم براشون لذت‌بخش باشه.
نکته‌ی جالبی که در مورد این برنامه هست اینه که نزدیک 108 میلیون نفر که بیشتر دانش‌آموز هستن تا به حال این برنامه رو انجام دادن و این برنامه از طرف افراد مهمی در تکنولوژی مثل بیل گیتس، استیو بالمر و مارک زاکربرگ تبلیغ و حمایت میشه. افراد مختلفی از قشرهای مختلف هم در فیلم‌های آموزشی این برنامه وجود دارن. مثلاً آموزش اولیه رو یک خانم مدل که برنامه‌نویس هم هست میده، یا شرط‌ها رو یک بسکتبالیست تدریس می‌کنه. این عمومیتی که در آموزش‌ها نمایش داده میشه به مردم نشون میده که هر کسی می‌تونه کد بنویسه و کسایی که کد می‌زنن آدمای عجیب‌غریبی نیستن. این بخصوص می‌تونه به دانش‌آموزها دید خوبی بده تا شاید حاضر بشن در آینده به علوم کامپیوتر بپردازن. با توجه به سیر تغییر دنیا، به نظر میرسه که آینده به مهندسان کامپیوتر بیش‌ازپیش نیاز خواهد داشت. حتی اگر کسی مهندس کامپیوتر هم نشد، باید حداقل سواد و شناختی در مورد  سیستم‌های کامپیوتری که در همه‌جا وجود دارن داشته باشن.&lt;/p&gt;

&lt;p&gt;انجام این برنامه رو به خواهرم پیشنهاد دادم و بعد از اتمام موفقیت‌آمیز این برنامه، این مدرک بهش داده شد که باعث شد هم خوشحال بشه و هم مشتاق‌تر بشه و تصمیم بگیره که بقیه‌ی دوره‌های برنامه‌نویسی این سایت رو انجام بده.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://blog.erfan.xyz/stylesheets/images/codeorg-hour-of-code-cert.jpg" alt="Code.org Hour of Code certificate" /&gt;&lt;/p&gt;

&lt;p&gt;من هم پیشنهاد می‌کنم این سایت رو به بچه‌های فامیل و آشنا و هر کسی که مشتاق باشه و یا از وسایل کامپیوتری استفاده بکنه معرفی بکنید، مطمئنم خیلی لذت خواهند برد و خیلی چیزها هم یاد خواهند گرفت.&lt;/p&gt;

&lt;p&gt;یک نکته‌ی مثبت دیگه هم اینه که این سایت نسخه‌ی فارسی هم داره. یادتون باشه از پایین صفحه زبان رو فارسی انتخاب کنید تا همه‌ی نوشته‌های سایت فارسی بشن. همچنین در این صورت زیرنویس ویدیوها هم فارسی میشه.&lt;/p&gt;

&lt;p&gt;امیدوارم که با همچین برنامه‌هایی، سواد عمومی از کامپیوترها حداقل در نسل آینده بیشتر باشه و کامپیوتر و گوشی و اینترنت رو فقط مساوی با وایبر و بازی‌هایی مثل Clash of Clans ندونیم (این دو تا رو گفتم چون فکر می‌کنم اینا بیشترین مصرف رو در جامعه‌ی ایران داشته باشن)&lt;/p&gt;
</summary><published>2015-03-23T19:30:00Z</published><updated>2015-03-23T19:30:00Z</updated><link rel="alternate" href="http://blog.erfan.xyz/2015/03/code-org/" /><content type="html">&lt;h1&gt;به نام خدا&lt;/h1&gt;

&lt;p&gt;شاید اسم برنامه‌ی «ساعتی با کد» یا "Hour of Code" رو شنیده باشید. هدف این برنامه اینه که در طی یک ساعت، تجربه‌ی ایجاد برنامه رو به افراد مختلف ارائه بکنه.&lt;br /&gt;
سایت &lt;a href="http://code.org"&gt;Code.org&lt;/a&gt; که موسس آن &lt;a href="http://code.org/about/leadership/hadi_partovi"&gt;هادی پرتوی&lt;/a&gt; هست، مجری این برنامه در جهان هست. در این سایت افراد می‌تونن در قالب کاراکترهای مشهوری مانند پرنده‌های بازی Angry Birds یا کاراکترهای انیمیشن Frozen تکه‌کدهایی بنویسن و تجربه‌ی برنامه‌نویسی رو داشته باشن. دوره‌ی اول کدنویسی در این سایت که حداکثر شاید یک ساعت طول بکشه یک برنامه‌ی مفرح و شاد هست که
فرد در طی اون در قالب یک محیط بازی، حرکت کاراکتر رو با استفاده از بلوک‌های اجرایی به عنوان تکه‌های کد، ایجاد می‌کنن.
در این محیط فرد با استفاده از برنامه‌نویسی بلوکی، به جای نوشتن کد به صورت متن، با استفاده از کدهایی منطق بازی رو پیاده‌سازی می‌کنه. در طی این یک ساعت مفاهیمی مثل خط‌به‌خط اجرا شدن کد، تکرار در کد (loop) و همچنین شرط در اجرای کد آموزش داده میشن. بدلیل سادگی محیط، تموم‌کردن ساعتی با کد حتی برای بچه‌ها هم ممکنه و فکر می‌کنم براشون لذت‌بخش باشه.
نکته‌ی جالبی که در مورد این برنامه هست اینه که نزدیک 108 میلیون نفر که بیشتر دانش‌آموز هستن تا به حال این برنامه رو انجام دادن و این برنامه از طرف افراد مهمی در تکنولوژی مثل بیل گیتس، استیو بالمر و مارک زاکربرگ تبلیغ و حمایت میشه. افراد مختلفی از قشرهای مختلف هم در فیلم‌های آموزشی این برنامه وجود دارن. مثلاً آموزش اولیه رو یک خانم مدل که برنامه‌نویس هم هست میده، یا شرط‌ها رو یک بسکتبالیست تدریس می‌کنه. این عمومیتی که در آموزش‌ها نمایش داده میشه به مردم نشون میده که هر کسی می‌تونه کد بنویسه و کسایی که کد می‌زنن آدمای عجیب‌غریبی نیستن. این بخصوص می‌تونه به دانش‌آموزها دید خوبی بده تا شاید حاضر بشن در آینده به علوم کامپیوتر بپردازن. با توجه به سیر تغییر دنیا، به نظر میرسه که آینده به مهندسان کامپیوتر بیش‌ازپیش نیاز خواهد داشت. حتی اگر کسی مهندس کامپیوتر هم نشد، باید حداقل سواد و شناختی در مورد  سیستم‌های کامپیوتری که در همه‌جا وجود دارن داشته باشن.&lt;/p&gt;

&lt;p&gt;انجام این برنامه رو به خواهرم پیشنهاد دادم و بعد از اتمام موفقیت‌آمیز این برنامه، این مدرک بهش داده شد که باعث شد هم خوشحال بشه و هم مشتاق‌تر بشه و تصمیم بگیره که بقیه‌ی دوره‌های برنامه‌نویسی این سایت رو انجام بده.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://blog.erfan.xyz/stylesheets/images/codeorg-hour-of-code-cert.jpg" alt="Code.org Hour of Code certificate" /&gt;&lt;/p&gt;

&lt;p&gt;من هم پیشنهاد می‌کنم این سایت رو به بچه‌های فامیل و آشنا و هر کسی که مشتاق باشه و یا از وسایل کامپیوتری استفاده بکنه معرفی بکنید، مطمئنم خیلی لذت خواهند برد و خیلی چیزها هم یاد خواهند گرفت.&lt;/p&gt;

&lt;p&gt;یک نکته‌ی مثبت دیگه هم اینه که این سایت نسخه‌ی فارسی هم داره. یادتون باشه از پایین صفحه زبان رو فارسی انتخاب کنید تا همه‌ی نوشته‌های سایت فارسی بشن. همچنین در این صورت زیرنویس ویدیوها هم فارسی میشه.&lt;/p&gt;

&lt;p&gt;امیدوارم که با همچین برنامه‌هایی، سواد عمومی از کامپیوترها حداقل در نسل آینده بیشتر باشه و کامپیوتر و گوشی و اینترنت رو فقط مساوی با وایبر و بازی‌هایی مثل Clash of Clans ندونیم (این دو تا رو گفتم چون فکر می‌کنم اینا بیشترین مصرف رو در جامعه‌ی ایران داشته باشن)&lt;/p&gt;
</content></entry><entry><id>http://blog.erfan.xyz/2015/03/ceemple-opencv-vs-extension/</id><title type="text">OpenCV آسان در ویندوز با استفاده از Ceemple</title><summary type="html">&lt;h1&gt;به نام خدا&lt;/h1&gt;

&lt;h2&gt;OpenCV&lt;/h2&gt;

&lt;p&gt;یکی از مهم‌ترین کتابخانه‌های پردازش تصویر و بینایی ماشین، کتابخانه‌ی &lt;a href="http://opencv.org"&gt;OpenCV&lt;/a&gt; هست. این کتابخانه که با استفاده از C/C++ نوشته شده و بسیاری از الگوریتم‌های مورد نیاز برای پردازش تصویر، بینایی ماشین و یادگیری ماشین رو پیاده‌سازی کرده. این کتابخانه از بسیاری از سیستم‌های عامل و معماری‌های سخت‌افزاری پشتیبانی می‌کنه و تقریباً همه جا می‌تونید ازش استفاده بکنید. همچنین اگر با زبان C++ راحت نباشید، این کتابخانه رو میشه به راحتی از زبان‌های جاوا و پایتون هم صدا زد و استفاده کرد.&lt;/p&gt;

&lt;p&gt;با توجه به اینکه این کتابخانه از نظر حجم کد و همچنین وابستگی‌های خارجی به کتابخانه‌های دیگه، یک کتابخانه‌ی بسیار بزرگ به حساب میاد، بنابراین آماده‌کردن اون برای استفاده کار نسبتاً سختیه. برای اینکه بتونید از این کتابخانه استفاده بکنید، لازمه که کد این کتابخانه، به همراه کتابخانه‌های خارجی دیگری که کد به اونها وابسته هست کامپایل بشن تا بعد بشه ازشون استفاده کرد. این کار، بخصوص بر روی ویندوز نسبتاً سخت و وقت‌گیر هست. در این پست قصد دارم راه‌حل آسانی رو برای حل این مشکل معرفی کنم. OpenCV سخت در ویندوز رو بعداً توضیح خواهم داد.&lt;/p&gt;

&lt;h2&gt;Ceemple OpenCV for Visual Studio&lt;/h2&gt;

&lt;h3&gt;&lt;a href="http://www.ceemple.com/ceemple-opencv-visual-studio/"&gt;دریافت این افزونه&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src="http://www.ceemple.com/wp-content/uploads/2015/01/Capture5-1024x555.png" alt="Ceemple OpenCV for Visual Studio" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="http://ceemple.com"&gt;Ceemple&lt;/a&gt; یک راه‌حل مناسب برای این مشکل ارائه داده. اونا یک extension برای ویژوال استودیو ارائه دادن که شامل OpenCV 3.0 کامپایل‌شده و آماده‌ی استفاده به همراه کتابخانه‌های جانبی مهمی مثل CUDA، OpenCL، OpenMP و IPP هست.
شاید اطلاع داشته باشید که خود OpenCV هم DLLهای از پیش‌ساخته‌شده‌ی کتابخانه رو برای ویندوز ارائه میده. ولی این فایل‌ها، با حداقل استفاده از کتابخانه‌های جانبی بخصوص CUDA و IPP ارائه میشن که این موضوع باعث میشه این کتابخانه از تمام امکانات سخت‌افزاری برای پردازش بهره نبره. ولی در نسخه‌ای که Ceemple ارائه میده، این کتابخانه‌های مهم جانبی وجود دارن و شما می‌تونید از سرعت بیشتر اجرای کد بر روی پردازنده‌ یا پردازنده‌ی گرافیکی خودتون استفاده کنید.&lt;/p&gt;

&lt;p&gt;همچنین با نصب این افزونه، امکان ساخت پروژه‌های OpenCV به صورت مستقیم از درون ویژوال استودیو ایجاد میشه. به این ترتیب خیلی سریع و بدون نیاز به تنظیم دسترسی پروژه به فایل‌های header و dll و lib مربوط به OpenCV و کتابخانه‌های جانبی، می‌تونید شروع به کد زدن بکنید و به تولید برنامه بپردازید.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.ceemple.com/wp-content/uploads/2015/01/Capture.png" alt="New OpenCV project dialoge in VS" /&gt;&lt;/p&gt;

&lt;p&gt;علاوه بر نکات مثبت گفته شده، با نصب این افزونه، افزونه‌ی &lt;a href="https://visualstudiogallery.msdn.microsoft.com/e682d542-7ef3-402c-b857-bbfba714f78d"&gt;Image Watch&lt;/a&gt; هم بر روی ویژوال استودیو نصب میشه. این افزونه‌ی بسیار مفید به شما در هنگام debug کردن برنامه در ویژوال استودیو کمک می‌کنه. با استفاده از این افزونه، در هنگام debug کردن، می‌تونید تصاویری که در کدتون استفاده می‌کنید و بر روی حافظه هستن رو ببینید و به راحتی به جریان کدتون پی ببرید و مشکلات احتمالی رو به راحتی پیدا و رفع کنید. این افزونه بسیار افزونه‌ی مفیدیه و برای کارهای پردازش تصویر و بینایی ماشین بسیار توصیه میشه.
(&lt;a href="http://channel9.msdn.com/posts/Introducing-Image-Watch"&gt;توضیح بیشتر در مورد Image Watch&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.ceemple.com/wp-content/uploads/2015/01/Capture7-1024x559.png" alt="Image Watch VS extension" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;توجه&lt;/strong&gt;: &lt;em&gt;تصاویر برگرفته از سایت &lt;a href="http://ceemple.com"&gt;ceemple&lt;/a&gt; هستند.&lt;/em&gt;&lt;/p&gt;

&lt;h2&gt;به‌روزرسانی 1&lt;/h2&gt;

&lt;p&gt;با استفاده از biicode هم می‌تونید به سادگی از OpenCV استفاده کنید. در این
&lt;a href="http://docs.opencv.org/master/d3/d82/tutorial_biicode.html"&gt;لینک&lt;/a&gt; در این مورد توضیح داده شده. &lt;/p&gt;
</summary><published>2015-03-19T20:30:00Z</published><updated>2015-03-19T20:30:00Z</updated><link rel="alternate" href="http://blog.erfan.xyz/2015/03/ceemple-opencv-vs-extension/" /><content type="html">&lt;h1&gt;به نام خدا&lt;/h1&gt;

&lt;h2&gt;OpenCV&lt;/h2&gt;

&lt;p&gt;یکی از مهم‌ترین کتابخانه‌های پردازش تصویر و بینایی ماشین، کتابخانه‌ی &lt;a href="http://opencv.org"&gt;OpenCV&lt;/a&gt; هست. این کتابخانه که با استفاده از C/C++ نوشته شده و بسیاری از الگوریتم‌های مورد نیاز برای پردازش تصویر، بینایی ماشین و یادگیری ماشین رو پیاده‌سازی کرده. این کتابخانه از بسیاری از سیستم‌های عامل و معماری‌های سخت‌افزاری پشتیبانی می‌کنه و تقریباً همه جا می‌تونید ازش استفاده بکنید. همچنین اگر با زبان C++ راحت نباشید، این کتابخانه رو میشه به راحتی از زبان‌های جاوا و پایتون هم صدا زد و استفاده کرد.&lt;/p&gt;

&lt;p&gt;با توجه به اینکه این کتابخانه از نظر حجم کد و همچنین وابستگی‌های خارجی به کتابخانه‌های دیگه، یک کتابخانه‌ی بسیار بزرگ به حساب میاد، بنابراین آماده‌کردن اون برای استفاده کار نسبتاً سختیه. برای اینکه بتونید از این کتابخانه استفاده بکنید، لازمه که کد این کتابخانه، به همراه کتابخانه‌های خارجی دیگری که کد به اونها وابسته هست کامپایل بشن تا بعد بشه ازشون استفاده کرد. این کار، بخصوص بر روی ویندوز نسبتاً سخت و وقت‌گیر هست. در این پست قصد دارم راه‌حل آسانی رو برای حل این مشکل معرفی کنم. OpenCV سخت در ویندوز رو بعداً توضیح خواهم داد.&lt;/p&gt;

&lt;h2&gt;Ceemple OpenCV for Visual Studio&lt;/h2&gt;

&lt;h3&gt;&lt;a href="http://www.ceemple.com/ceemple-opencv-visual-studio/"&gt;دریافت این افزونه&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src="http://www.ceemple.com/wp-content/uploads/2015/01/Capture5-1024x555.png" alt="Ceemple OpenCV for Visual Studio" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="http://ceemple.com"&gt;Ceemple&lt;/a&gt; یک راه‌حل مناسب برای این مشکل ارائه داده. اونا یک extension برای ویژوال استودیو ارائه دادن که شامل OpenCV 3.0 کامپایل‌شده و آماده‌ی استفاده به همراه کتابخانه‌های جانبی مهمی مثل CUDA، OpenCL، OpenMP و IPP هست.
شاید اطلاع داشته باشید که خود OpenCV هم DLLهای از پیش‌ساخته‌شده‌ی کتابخانه رو برای ویندوز ارائه میده. ولی این فایل‌ها، با حداقل استفاده از کتابخانه‌های جانبی بخصوص CUDA و IPP ارائه میشن که این موضوع باعث میشه این کتابخانه از تمام امکانات سخت‌افزاری برای پردازش بهره نبره. ولی در نسخه‌ای که Ceemple ارائه میده، این کتابخانه‌های مهم جانبی وجود دارن و شما می‌تونید از سرعت بیشتر اجرای کد بر روی پردازنده‌ یا پردازنده‌ی گرافیکی خودتون استفاده کنید.&lt;/p&gt;

&lt;p&gt;همچنین با نصب این افزونه، امکان ساخت پروژه‌های OpenCV به صورت مستقیم از درون ویژوال استودیو ایجاد میشه. به این ترتیب خیلی سریع و بدون نیاز به تنظیم دسترسی پروژه به فایل‌های header و dll و lib مربوط به OpenCV و کتابخانه‌های جانبی، می‌تونید شروع به کد زدن بکنید و به تولید برنامه بپردازید.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.ceemple.com/wp-content/uploads/2015/01/Capture.png" alt="New OpenCV project dialoge in VS" /&gt;&lt;/p&gt;

&lt;p&gt;علاوه بر نکات مثبت گفته شده، با نصب این افزونه، افزونه‌ی &lt;a href="https://visualstudiogallery.msdn.microsoft.com/e682d542-7ef3-402c-b857-bbfba714f78d"&gt;Image Watch&lt;/a&gt; هم بر روی ویژوال استودیو نصب میشه. این افزونه‌ی بسیار مفید به شما در هنگام debug کردن برنامه در ویژوال استودیو کمک می‌کنه. با استفاده از این افزونه، در هنگام debug کردن، می‌تونید تصاویری که در کدتون استفاده می‌کنید و بر روی حافظه هستن رو ببینید و به راحتی به جریان کدتون پی ببرید و مشکلات احتمالی رو به راحتی پیدا و رفع کنید. این افزونه بسیار افزونه‌ی مفیدیه و برای کارهای پردازش تصویر و بینایی ماشین بسیار توصیه میشه.
(&lt;a href="http://channel9.msdn.com/posts/Introducing-Image-Watch"&gt;توضیح بیشتر در مورد Image Watch&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.ceemple.com/wp-content/uploads/2015/01/Capture7-1024x559.png" alt="Image Watch VS extension" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;توجه&lt;/strong&gt;: &lt;em&gt;تصاویر برگرفته از سایت &lt;a href="http://ceemple.com"&gt;ceemple&lt;/a&gt; هستند.&lt;/em&gt;&lt;/p&gt;

&lt;h2&gt;به‌روزرسانی 1&lt;/h2&gt;

&lt;p&gt;با استفاده از biicode هم می‌تونید به سادگی از OpenCV استفاده کنید. در این
&lt;a href="http://docs.opencv.org/master/d3/d82/tutorial_biicode.html"&gt;لینک&lt;/a&gt; در این مورد توضیح داده شده. &lt;/p&gt;
</content></entry><entry><id>http://blog.erfan.xyz/2015/02/installing-theano/</id><title type="text">نصب کتابخانه‌ی Theano در ویندوز</title><summary type="html">&lt;h1&gt;به نام خدا&lt;/h1&gt;

&lt;p&gt;یکی از مهم‌ترین برتری‌های زبان پایتون، مجموعه‌ی بسیار کامل کتابخانه‌هایی هست که برای کارهای مختلف در دسترس برنامه‌نویس هست. این موضوع باعث شده که برای کاربردهای بسیاری، بتوان کتابخانه‌های بسیار با کیفیتی پیدا کرد و از اونها استفاده کرد.&lt;/p&gt;

&lt;p&gt;یکی از حوزه‌هایی که از این مورد مستثنی نیست، موضوع کتابخانه‌های مربوط به &lt;em&gt;یادگیری عمیق&lt;/em&gt; یا &lt;em&gt;Deep Learning&lt;/em&gt; هست. از روی مشاهداتم می‌تونم بگم که بیشترین کتابخانه‌ها برای اینکار رو زبان پایتون داره و حتی اگر کتابخانه‌ای مثلاً در زبانی مثل C++ نوشته شده باشه، به احتمال زیادی یک پوشش (wrapper) برای زبان پایتون داره.&lt;/p&gt;

&lt;p&gt;یک منبع مناسب که تعدادی از کتابخانه‌های مربوط به یادگیری عمیق رو با هم مقایسه کرده،
&lt;a href="https://github.com/soumith/convnet-benchmarks"&gt;soumith/convnet-benchmarks&lt;/a&gt;
 هست. در اینجا می‌تونیم ببینیم که سهم زبان‌های Python و Lua در کنار زبان C++ از کتابخانه‌های با کیفیت و مطرح بالا است.&lt;/p&gt;

&lt;p&gt;مشکلی که بسیاری از این کتابخانه‌ها دارن اینه که با در نظر گرفتن ویندوز ایجاد نشدن. بخاطر همین نمیشه به راحتی خیلی از اونها رو در ویندوز استفاده کرد. برای کاری که می‌خوام انجام بدم تصمیم گرفتم این کتابخانه‌ها رو با هم مقایسه کنم و نهایت سعی‌ام رو بکنم که روی ویندوز اجراشون کنم. در ابتدا و بخاطر اینکه خیلی بیشتر ازش استفاده میشه، از کتابخانه‌ی Theano شروع کردم.&lt;/p&gt;

&lt;h2&gt;معرفی &lt;a href="http://www.deeplearning.net/software/theano/"&gt;Theano&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;طبق تعریفی که در خود سایت نوشته شده، &lt;em&gt;Theano&lt;/em&gt; «یک کتابخانه برای تعریف، بهینه‌سازی و اجرای عبارت‌های ریاضی شامل آرایه‌های چندبعدی به صورت بهینه است.»&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Theano is a Python library that allows you to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;از ویژگی‌های این کتابخانه میشه به تعامل با کتابخانه‌ی NumPy (استفاده از &lt;code&gt;numpy.ndarray&lt;/code&gt;)، استفاده از واحد پردازش گرافیکی برای تسریع عملیات، مشتق‌گیری سریع عبارت‌های ریاضی و همچنین تولید پویای کد به زبان C اشاره کرد.
 این کتابخانه توسط آزمایشگاه LISA دانشگاه مونترال کانادا تهیه میشه و معمولاً شامل جدیدترین الگوریتم‌ها و معماری شبکه‌های عمیق از جدیدترین مقالات هست.&lt;/p&gt;

&lt;h3&gt;نصب Theano&lt;/h3&gt;

&lt;p&gt;با وجود اینکه در ابتدا تصور می‌کردم نصب این کتابخانه، با توجه به اینکه از CUDA هم استفاده می‌کنه، در ویندوز کار بسیار سختی خواهد بود، ولی به هیچ عنوان اینگونه نبود. برای نصب این کتابخانه ابتدا آخرین نسخه‌ی کد رو با استفاده از دستور زیر از گیت‌هاب گرفتم:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git clone https://github.com/Theano/Theano
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;بعد از گرفتن کد مربوط به این کتابخانه، در مسیر کاربری خودم در ویندوز، یعنی &lt;code&gt;C:\Users\&amp;lt;username&amp;gt;\&lt;/code&gt;، یک فایل با نام &lt;code&gt;.theanorc&lt;/code&gt; ایجاد کردم تا بتونم در این فایل تنظیماتی رو به این کتابخانه بدم. تنظیمات مربوط به طور کامل در &lt;a href="http://www.deeplearning.net/software/theano/install.html#bleeding-edge-installation"&gt;این آدرس&lt;/a&gt; نوشته شده. بعد از اینکه فایل تنظیمات مورد نظر رو تکمیل کردم (تنظیمات مربوط به CUDA رو هم اعمال کردم) با دستور زیر کتابخانه ساخت و نصب شد، به همین سادگی&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd theano
python setup.py install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;برای اینکه ببینید استفاده از کارت گرافیکی در این کتابخانه، به طور خاص، و کتابخانه، به طور عام درست ساخت و نصب شده، از آدرس زیر برنامه‌ی مورد نظر رو اجرا کنید:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd theano\misc
python check_blas.py
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;&lt;a href="https://github.com/lisa-lab/pylearn2"&gt;Pylearn2&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;کتابخانه‌ی Pylearn2 یک کتابخانه‌ی یادگیری ماشین هست که بر روی کتابخانه‌ی Theano توسط آزمایشگاه LISA ایجاد شده. این کتابخانه به سرعت در حال تغییره و الگوریتم‌های بسیاری بهش اضافه میشن. به نظر میومد که نصب این کتابخانه چون وابسته به theano بود خیلی سخت نباشه، ولی اینطوری نبود. طبق معمول بقیه‌ی کتابخانه‌ها، کد این کتابخانه رو از روی گیت‌هاب گرفتم. بعد که خواستم نصبش کنم، با این خطا مواجه شدم که نمی‌تونست کامپایلر Microsoft Visual C++ 2008 یا همون VC90 رو پیدا بکنه. قبلاً هم این مشکل رو داشتم ولی تونسته بودم حلش کنم (&lt;a href="http://erfannoury.github.io/2014/04/msvc-for-python/"&gt;در اینجا توضیح دادم چطوری&lt;/a&gt;)،ولی این بار متاسفانه مشکل به این راحتی حل نشد.&lt;/p&gt;

&lt;p&gt;با وجود اینکه تنظیمات رو تغییر دادم تا از کامپایلر Microsoft Visual C++ 2013 یا همون VC120 استفاده بشه، ولی باز درخواست کامپایر قدیمی رو می‌کرد. چاره‌ای نداشتم جز اینکه این کامپایلر رو نصب کنم. خوشبختانه برای حل این مشکل مایکروسافت یک دانلود کم حجم از این نسخه از کامپایلر برای پایتون 2.7 قرار داده.
&lt;a href="http://aka.ms/vcpython27"&gt;از این آدرس&lt;/a&gt; میشه این نسخه از کامپایلر رو دانلود کرد. بعد از نصب این نسخه‌ی قدیمی از کامپایلر مشکل پیدا کردنش حل شد، ولی در کل استفاده از چنین نسخه‌ی قدیمی مشکل‌سازه. از توی کد کتابخانه نتونستم چیزی پیدا کنم که مربوط به محدودیت استفاده از این نسخه از کامپایلر باشه، بنابراین حدس می‌زنم که مشکل از setuptools پایتون هست. بعد از کمی جستجو و پیدا کردن پروژه‌ای موسوم به &lt;a href="http://pythonwheels.com/"&gt;Python Wheels&lt;/a&gt; حدسم قوت گرفت. فکر می‌کنم مشکل از همین باشه و این پروژه سعی داره این مشکل رو حل بکنه. فعلاً که خیلی از کتابخانه‌های مطرح پایتون از این پروژه پشتیبانی نمی‌کنن، چه برسه به پروژه‌ای مثل Pylearn2. خلاصه در نهایت مجبور به استفاده از همین نسخه از کامپایلر شدم.&lt;/p&gt;

&lt;p&gt;بعد از حل مشکل اومدم و طبق گفته‌ی سایت از دستور زیر برای نصب استفاده کردم&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;python setup.py develop
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ولی در نهایت تاسف، با پیام خطای زیر در مورد یکی از فایل‌ها مواجه شدم.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;LINK : fatal error LNK1181: cannot open input file 'Vault\Github\pylearn2\pylearn2\utils\_window_flip.pyd'
error: Command "C:\Users\Erfan\AppData\Local\Programs\Common\Microsoft\Visual C++ for Python\9.0\VC\Bin\amd64\link.exe /DLL /nologo /INCREMENTAL:NO /LIBPATH:C:\Anaconda\libs /LIBPATH:C:\Anaconda\PCbuild\amd64 /EXPORT:init_window_flip build\temp.win-amd64-2.7\Release\pylearn2/utils\_window_flip.obj /OUT:E:\Code Vault\Github\pylearn2\pylearn2\utils\_window_flip.pyd /IMPLIB:build\temp.win-amd64-2.7\Release\pylearn2/utils\_window_flip.lib /MANIFESTFILE:build\temp.win-amd64-2.7\Release\pylearn2/utils\_window_flip.pyd.manifest" failed with exit status 1181
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;راستش فعلاً پیدا نکردم که مشکل از چیه و چطوری میشه حلش کرد (به صورت اصولی)، ولی به جاش از دستور زیر برای نصب استفاده کردم و بدون مشکل کتابخانه نصب شد&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;python setup.py install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;بعد از این کار و نصب ظاهراً موفق این کتابخانه، با اجرای دستور &lt;code&gt;import pylearn2&lt;/code&gt;، پیام اخطاری مشاهده نشد. بنابراین احتمالاً بدون خطا نصب شده. البته باید بیشتر از کتابخانه استفاده بکنم تا بفهمم که آیا درست نصب شده یا نه.&lt;/p&gt;

&lt;h2&gt;&lt;a href="https://github.com/benanne/Lasagne"&gt;Lasagne&lt;/a&gt;, &lt;a href="https://github.com/bartvm/blocks"&gt;blocks&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;این دو کتابخانه به طور خاص برای ساخت شبکه‌های عصبی و بخصوص شبکه‌های عمیق ساخته شدن. هر دو مبتنی بر Theano هستن و هدف هر دو ساده‌تر کردن و ماژولار کردن ساخت این شبکه‌ها و پیاده‌سازی یادگیری این شبکه‌ها است.&lt;/p&gt;

&lt;p&gt;نصب این دو کتابخانه هم خیلی ساده بود. بعد از این که کد هر کدوم رو از گیت‌هاب گرفتم، با دستور &lt;code&gt;python setup.py install&lt;/code&gt; هر دو به سادگی نصب شدن.&lt;/p&gt;

&lt;h2&gt;جمع‌بندی&lt;/h2&gt;

&lt;p&gt;در نهایت همونطوری که گفتم، تونستم یکی از کتابخانه‌های مهم پایتون و همچنین سه تا از کتابخانه‌های مهم یادگیری عمیق رو بر روی ویندوز نصب کنم.&lt;/p&gt;

&lt;p&gt;لازم هست بگم که از Windows 8.1 Pro x64 و CUDA 6.5 بر روی nVidia Quadro K1100M استفاده می‌کنم. همچنین پایتون رو با استفاده از &lt;a href="https://store.continuum.io/cshop/anaconda/"&gt;Anaconda&lt;/a&gt; روی ویندوز نصب کردم؛ نسخه‌ی 2.7.6 پایتون بر روی Anaconda نسخه‌ی 2.0 به طور دقیق‌تر. نصب پایتون رو از این طریق خیلی پیشنهاد می‌کنم. چون بسیاری از کتابخانه‌های مهم پایتون همراه باهاش نصب میشن و یه IDE خوب به نام Spyder هم نصب میشه که خیلی می‌تونه کمک دست خوبی باشه.&lt;/p&gt;

&lt;p&gt;این از مرحله‌ی نصب این کتابخانه‌ها که به نظر می‌رسه با موفقیت به اتمام رسید. حالا می‌مونه استفاده از این کتابخانه‌ها و کار مفید انجام دادن باهاشون که البته مرحله‌ی مهم‌تریه.&lt;/p&gt;

&lt;p&gt;در آینده، انشالله، بیشتر در موردشون خواهم نوشت.&lt;/p&gt;
</summary><published>2015-02-12T20:30:00Z</published><updated>2015-02-12T20:30:00Z</updated><link rel="alternate" href="http://blog.erfan.xyz/2015/02/installing-theano/" /><content type="html">&lt;h1&gt;به نام خدا&lt;/h1&gt;

&lt;p&gt;یکی از مهم‌ترین برتری‌های زبان پایتون، مجموعه‌ی بسیار کامل کتابخانه‌هایی هست که برای کارهای مختلف در دسترس برنامه‌نویس هست. این موضوع باعث شده که برای کاربردهای بسیاری، بتوان کتابخانه‌های بسیار با کیفیتی پیدا کرد و از اونها استفاده کرد.&lt;/p&gt;

&lt;p&gt;یکی از حوزه‌هایی که از این مورد مستثنی نیست، موضوع کتابخانه‌های مربوط به &lt;em&gt;یادگیری عمیق&lt;/em&gt; یا &lt;em&gt;Deep Learning&lt;/em&gt; هست. از روی مشاهداتم می‌تونم بگم که بیشترین کتابخانه‌ها برای اینکار رو زبان پایتون داره و حتی اگر کتابخانه‌ای مثلاً در زبانی مثل C++ نوشته شده باشه، به احتمال زیادی یک پوشش (wrapper) برای زبان پایتون داره.&lt;/p&gt;

&lt;p&gt;یک منبع مناسب که تعدادی از کتابخانه‌های مربوط به یادگیری عمیق رو با هم مقایسه کرده،
&lt;a href="https://github.com/soumith/convnet-benchmarks"&gt;soumith/convnet-benchmarks&lt;/a&gt;
 هست. در اینجا می‌تونیم ببینیم که سهم زبان‌های Python و Lua در کنار زبان C++ از کتابخانه‌های با کیفیت و مطرح بالا است.&lt;/p&gt;

&lt;p&gt;مشکلی که بسیاری از این کتابخانه‌ها دارن اینه که با در نظر گرفتن ویندوز ایجاد نشدن. بخاطر همین نمیشه به راحتی خیلی از اونها رو در ویندوز استفاده کرد. برای کاری که می‌خوام انجام بدم تصمیم گرفتم این کتابخانه‌ها رو با هم مقایسه کنم و نهایت سعی‌ام رو بکنم که روی ویندوز اجراشون کنم. در ابتدا و بخاطر اینکه خیلی بیشتر ازش استفاده میشه، از کتابخانه‌ی Theano شروع کردم.&lt;/p&gt;

&lt;h2&gt;معرفی &lt;a href="http://www.deeplearning.net/software/theano/"&gt;Theano&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;طبق تعریفی که در خود سایت نوشته شده، &lt;em&gt;Theano&lt;/em&gt; «یک کتابخانه برای تعریف، بهینه‌سازی و اجرای عبارت‌های ریاضی شامل آرایه‌های چندبعدی به صورت بهینه است.»&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Theano is a Python library that allows you to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;از ویژگی‌های این کتابخانه میشه به تعامل با کتابخانه‌ی NumPy (استفاده از &lt;code&gt;numpy.ndarray&lt;/code&gt;)، استفاده از واحد پردازش گرافیکی برای تسریع عملیات، مشتق‌گیری سریع عبارت‌های ریاضی و همچنین تولید پویای کد به زبان C اشاره کرد.
 این کتابخانه توسط آزمایشگاه LISA دانشگاه مونترال کانادا تهیه میشه و معمولاً شامل جدیدترین الگوریتم‌ها و معماری شبکه‌های عمیق از جدیدترین مقالات هست.&lt;/p&gt;

&lt;h3&gt;نصب Theano&lt;/h3&gt;

&lt;p&gt;با وجود اینکه در ابتدا تصور می‌کردم نصب این کتابخانه، با توجه به اینکه از CUDA هم استفاده می‌کنه، در ویندوز کار بسیار سختی خواهد بود، ولی به هیچ عنوان اینگونه نبود. برای نصب این کتابخانه ابتدا آخرین نسخه‌ی کد رو با استفاده از دستور زیر از گیت‌هاب گرفتم:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git clone https://github.com/Theano/Theano
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;بعد از گرفتن کد مربوط به این کتابخانه، در مسیر کاربری خودم در ویندوز، یعنی &lt;code&gt;C:\Users\&amp;lt;username&amp;gt;\&lt;/code&gt;، یک فایل با نام &lt;code&gt;.theanorc&lt;/code&gt; ایجاد کردم تا بتونم در این فایل تنظیماتی رو به این کتابخانه بدم. تنظیمات مربوط به طور کامل در &lt;a href="http://www.deeplearning.net/software/theano/install.html#bleeding-edge-installation"&gt;این آدرس&lt;/a&gt; نوشته شده. بعد از اینکه فایل تنظیمات مورد نظر رو تکمیل کردم (تنظیمات مربوط به CUDA رو هم اعمال کردم) با دستور زیر کتابخانه ساخت و نصب شد، به همین سادگی&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd theano
python setup.py install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;برای اینکه ببینید استفاده از کارت گرافیکی در این کتابخانه، به طور خاص، و کتابخانه، به طور عام درست ساخت و نصب شده، از آدرس زیر برنامه‌ی مورد نظر رو اجرا کنید:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd theano\misc
python check_blas.py
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;&lt;a href="https://github.com/lisa-lab/pylearn2"&gt;Pylearn2&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;کتابخانه‌ی Pylearn2 یک کتابخانه‌ی یادگیری ماشین هست که بر روی کتابخانه‌ی Theano توسط آزمایشگاه LISA ایجاد شده. این کتابخانه به سرعت در حال تغییره و الگوریتم‌های بسیاری بهش اضافه میشن. به نظر میومد که نصب این کتابخانه چون وابسته به theano بود خیلی سخت نباشه، ولی اینطوری نبود. طبق معمول بقیه‌ی کتابخانه‌ها، کد این کتابخانه رو از روی گیت‌هاب گرفتم. بعد که خواستم نصبش کنم، با این خطا مواجه شدم که نمی‌تونست کامپایلر Microsoft Visual C++ 2008 یا همون VC90 رو پیدا بکنه. قبلاً هم این مشکل رو داشتم ولی تونسته بودم حلش کنم (&lt;a href="http://erfannoury.github.io/2014/04/msvc-for-python/"&gt;در اینجا توضیح دادم چطوری&lt;/a&gt;)،ولی این بار متاسفانه مشکل به این راحتی حل نشد.&lt;/p&gt;

&lt;p&gt;با وجود اینکه تنظیمات رو تغییر دادم تا از کامپایلر Microsoft Visual C++ 2013 یا همون VC120 استفاده بشه، ولی باز درخواست کامپایر قدیمی رو می‌کرد. چاره‌ای نداشتم جز اینکه این کامپایلر رو نصب کنم. خوشبختانه برای حل این مشکل مایکروسافت یک دانلود کم حجم از این نسخه از کامپایلر برای پایتون 2.7 قرار داده.
&lt;a href="http://aka.ms/vcpython27"&gt;از این آدرس&lt;/a&gt; میشه این نسخه از کامپایلر رو دانلود کرد. بعد از نصب این نسخه‌ی قدیمی از کامپایلر مشکل پیدا کردنش حل شد، ولی در کل استفاده از چنین نسخه‌ی قدیمی مشکل‌سازه. از توی کد کتابخانه نتونستم چیزی پیدا کنم که مربوط به محدودیت استفاده از این نسخه از کامپایلر باشه، بنابراین حدس می‌زنم که مشکل از setuptools پایتون هست. بعد از کمی جستجو و پیدا کردن پروژه‌ای موسوم به &lt;a href="http://pythonwheels.com/"&gt;Python Wheels&lt;/a&gt; حدسم قوت گرفت. فکر می‌کنم مشکل از همین باشه و این پروژه سعی داره این مشکل رو حل بکنه. فعلاً که خیلی از کتابخانه‌های مطرح پایتون از این پروژه پشتیبانی نمی‌کنن، چه برسه به پروژه‌ای مثل Pylearn2. خلاصه در نهایت مجبور به استفاده از همین نسخه از کامپایلر شدم.&lt;/p&gt;

&lt;p&gt;بعد از حل مشکل اومدم و طبق گفته‌ی سایت از دستور زیر برای نصب استفاده کردم&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;python setup.py develop
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ولی در نهایت تاسف، با پیام خطای زیر در مورد یکی از فایل‌ها مواجه شدم.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;LINK : fatal error LNK1181: cannot open input file 'Vault\Github\pylearn2\pylearn2\utils\_window_flip.pyd'
error: Command "C:\Users\Erfan\AppData\Local\Programs\Common\Microsoft\Visual C++ for Python\9.0\VC\Bin\amd64\link.exe /DLL /nologo /INCREMENTAL:NO /LIBPATH:C:\Anaconda\libs /LIBPATH:C:\Anaconda\PCbuild\amd64 /EXPORT:init_window_flip build\temp.win-amd64-2.7\Release\pylearn2/utils\_window_flip.obj /OUT:E:\Code Vault\Github\pylearn2\pylearn2\utils\_window_flip.pyd /IMPLIB:build\temp.win-amd64-2.7\Release\pylearn2/utils\_window_flip.lib /MANIFESTFILE:build\temp.win-amd64-2.7\Release\pylearn2/utils\_window_flip.pyd.manifest" failed with exit status 1181
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;راستش فعلاً پیدا نکردم که مشکل از چیه و چطوری میشه حلش کرد (به صورت اصولی)، ولی به جاش از دستور زیر برای نصب استفاده کردم و بدون مشکل کتابخانه نصب شد&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;python setup.py install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;بعد از این کار و نصب ظاهراً موفق این کتابخانه، با اجرای دستور &lt;code&gt;import pylearn2&lt;/code&gt;، پیام اخطاری مشاهده نشد. بنابراین احتمالاً بدون خطا نصب شده. البته باید بیشتر از کتابخانه استفاده بکنم تا بفهمم که آیا درست نصب شده یا نه.&lt;/p&gt;

&lt;h2&gt;&lt;a href="https://github.com/benanne/Lasagne"&gt;Lasagne&lt;/a&gt;, &lt;a href="https://github.com/bartvm/blocks"&gt;blocks&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;این دو کتابخانه به طور خاص برای ساخت شبکه‌های عصبی و بخصوص شبکه‌های عمیق ساخته شدن. هر دو مبتنی بر Theano هستن و هدف هر دو ساده‌تر کردن و ماژولار کردن ساخت این شبکه‌ها و پیاده‌سازی یادگیری این شبکه‌ها است.&lt;/p&gt;

&lt;p&gt;نصب این دو کتابخانه هم خیلی ساده بود. بعد از این که کد هر کدوم رو از گیت‌هاب گرفتم، با دستور &lt;code&gt;python setup.py install&lt;/code&gt; هر دو به سادگی نصب شدن.&lt;/p&gt;

&lt;h2&gt;جمع‌بندی&lt;/h2&gt;

&lt;p&gt;در نهایت همونطوری که گفتم، تونستم یکی از کتابخانه‌های مهم پایتون و همچنین سه تا از کتابخانه‌های مهم یادگیری عمیق رو بر روی ویندوز نصب کنم.&lt;/p&gt;

&lt;p&gt;لازم هست بگم که از Windows 8.1 Pro x64 و CUDA 6.5 بر روی nVidia Quadro K1100M استفاده می‌کنم. همچنین پایتون رو با استفاده از &lt;a href="https://store.continuum.io/cshop/anaconda/"&gt;Anaconda&lt;/a&gt; روی ویندوز نصب کردم؛ نسخه‌ی 2.7.6 پایتون بر روی Anaconda نسخه‌ی 2.0 به طور دقیق‌تر. نصب پایتون رو از این طریق خیلی پیشنهاد می‌کنم. چون بسیاری از کتابخانه‌های مهم پایتون همراه باهاش نصب میشن و یه IDE خوب به نام Spyder هم نصب میشه که خیلی می‌تونه کمک دست خوبی باشه.&lt;/p&gt;

&lt;p&gt;این از مرحله‌ی نصب این کتابخانه‌ها که به نظر می‌رسه با موفقیت به اتمام رسید. حالا می‌مونه استفاده از این کتابخانه‌ها و کار مفید انجام دادن باهاشون که البته مرحله‌ی مهم‌تریه.&lt;/p&gt;

&lt;p&gt;در آینده، انشالله، بیشتر در موردشون خواهم نوشت.&lt;/p&gt;
</content></entry><entry><id>http://blog.erfan.xyz/2015/01/computers-which-learn/</id><title type="text">کامپیوترهایی که یاد می‌گیرند</title><summary type="html">&lt;h1&gt;به نام خدا&lt;/h1&gt;

&lt;p&gt;امروز یک ویدیو بسیار جالب از TEDxBrussels میدیدم در مورد کامپیوترهایی که می‌توانند یاد بگیرند. جای تعجب نداره که صحبت در مورد پیشرفت‌هایی بود که از طریق به کارگیری چارچون یادگیری موسوم به یادگیری عمیق (Deep Learning) به دست آمده. باز صحبت در مورد این بود که کامپیوترها قراره بسیاری از شغل‌های انسانی رو در اختیار بگیرن. ولی در این صحبت روی دو جنبه‌ی دیگه هم بحث کوتاهی شد که کمتر قبلاً دیده بودم.&lt;/p&gt;

&lt;p&gt;اول اینکه انسان به همراه کامپیوتر در بسیاری از کارها می‌تونن بسیار کارآمدتر و هوشمندتر عمل کنن. این دید متفاوتیه از این دید غالب و تاریخی که کامپیوترها رو در مقابل انسان‌ها قرار میده. البته بحث در مورد اینکه آیا واقعاً روزی کامپیوترهای هوشمند در مقابل انسان قرار خواهند گرفت یک بحث طولانی هست که نیاز به چند پست دیگه و مطالعات بیشتری از جانب من داره. ولی این دید حداقل در چشم‌انداز آینده‌ای نزدیک دیدی هست که می‌تونه بسیار مفید باشه و چیزی هست که واقعاً باهاش مواجه خواهیم شد. در این مورد یک demo خیلی جالب هم نشون میده.&lt;/p&gt;

&lt;p&gt;موضوع دیگه، هر چند مرتبط به موضوع قبلی، در مورد اثر کامپیوترها بر کشورهای کمتر توسعه ‌یافته یا بهتره بگم کشورهای غیر جهان اول هست. اگر به توزیع شغل‌ها در این کشورها نگاهی بیاندازیم، بیشتر ای شغل‌ها به سرعت و راحتی می‌تونن با سیستم‌های کامپیوتری جایگزین بشن و این کار می‌تونه اثر بسیار بزرگی بر اقتصاد این کشورها که  بیشتر جمعیت دنیا رو هم تشکیل میدن داشته باشه.&lt;/p&gt;

&lt;p&gt;به هر حال مسئله‌ی هوشمند شدن سیستم‌های کامپیوتری مسئله‌ای هست که بشر برای اولین بار داره در طول تاریخ باهاش مواجه میشه و باید برای عواقب این تغییر آماده باشیم و در موردش فکر کرده باشیم. الان میشه گفت کامپیوترها در بیشتر کارها به حد بالایی از هوشمندی رسیدن و با نرخ بالایی هوشمندی اونها داره بالاتر هم میره. پس در وحله‌ی اول باید در مورد رفتارمون در مقابل این هوشمندی و اثراتش فکر کنیم و چاره بیاندیشیم. و به این موضوع هم توجه کنیم که هوشمندی مقوله‌ای جدا از خودآگاهیه.&lt;/p&gt;

&lt;p&gt;این هم ویدیویی که در موردش گفتم، با سخنرانی آقای Jeremy Howard&lt;/p&gt;

&lt;iframe src="https://embed-ssl.ted.com/talks/jeremy_howard_the_wonderful_and_terrifying_implications_of_computers_that_can_learn.html" width="854" height="480" frameborder="0" scrolling="no" webkitAllowFullScreen mozallowfullscreen allowFullScreen&gt;&lt;/iframe&gt;
</summary><published>2015-01-08T20:30:00Z</published><updated>2015-01-08T20:30:00Z</updated><link rel="alternate" href="http://blog.erfan.xyz/2015/01/computers-which-learn/" /><content type="html">&lt;h1&gt;به نام خدا&lt;/h1&gt;

&lt;p&gt;امروز یک ویدیو بسیار جالب از TEDxBrussels میدیدم در مورد کامپیوترهایی که می‌توانند یاد بگیرند. جای تعجب نداره که صحبت در مورد پیشرفت‌هایی بود که از طریق به کارگیری چارچون یادگیری موسوم به یادگیری عمیق (Deep Learning) به دست آمده. باز صحبت در مورد این بود که کامپیوترها قراره بسیاری از شغل‌های انسانی رو در اختیار بگیرن. ولی در این صحبت روی دو جنبه‌ی دیگه هم بحث کوتاهی شد که کمتر قبلاً دیده بودم.&lt;/p&gt;

&lt;p&gt;اول اینکه انسان به همراه کامپیوتر در بسیاری از کارها می‌تونن بسیار کارآمدتر و هوشمندتر عمل کنن. این دید متفاوتیه از این دید غالب و تاریخی که کامپیوترها رو در مقابل انسان‌ها قرار میده. البته بحث در مورد اینکه آیا واقعاً روزی کامپیوترهای هوشمند در مقابل انسان قرار خواهند گرفت یک بحث طولانی هست که نیاز به چند پست دیگه و مطالعات بیشتری از جانب من داره. ولی این دید حداقل در چشم‌انداز آینده‌ای نزدیک دیدی هست که می‌تونه بسیار مفید باشه و چیزی هست که واقعاً باهاش مواجه خواهیم شد. در این مورد یک demo خیلی جالب هم نشون میده.&lt;/p&gt;

&lt;p&gt;موضوع دیگه، هر چند مرتبط به موضوع قبلی، در مورد اثر کامپیوترها بر کشورهای کمتر توسعه ‌یافته یا بهتره بگم کشورهای غیر جهان اول هست. اگر به توزیع شغل‌ها در این کشورها نگاهی بیاندازیم، بیشتر ای شغل‌ها به سرعت و راحتی می‌تونن با سیستم‌های کامپیوتری جایگزین بشن و این کار می‌تونه اثر بسیار بزرگی بر اقتصاد این کشورها که  بیشتر جمعیت دنیا رو هم تشکیل میدن داشته باشه.&lt;/p&gt;

&lt;p&gt;به هر حال مسئله‌ی هوشمند شدن سیستم‌های کامپیوتری مسئله‌ای هست که بشر برای اولین بار داره در طول تاریخ باهاش مواجه میشه و باید برای عواقب این تغییر آماده باشیم و در موردش فکر کرده باشیم. الان میشه گفت کامپیوترها در بیشتر کارها به حد بالایی از هوشمندی رسیدن و با نرخ بالایی هوشمندی اونها داره بالاتر هم میره. پس در وحله‌ی اول باید در مورد رفتارمون در مقابل این هوشمندی و اثراتش فکر کنیم و چاره بیاندیشیم. و به این موضوع هم توجه کنیم که هوشمندی مقوله‌ای جدا از خودآگاهیه.&lt;/p&gt;

&lt;p&gt;این هم ویدیویی که در موردش گفتم، با سخنرانی آقای Jeremy Howard&lt;/p&gt;

&lt;iframe src="https://embed-ssl.ted.com/talks/jeremy_howard_the_wonderful_and_terrifying_implications_of_computers_that_can_learn.html" width="854" height="480" frameborder="0" scrolling="no" webkitAllowFullScreen mozallowfullscreen allowFullScreen&gt;&lt;/iframe&gt;
</content></entry><entry><id>http://blog.erfan.xyz/2014/12/my-year-in-pocket/</id><title type="text">سال 2014 با پاکت</title><summary type="html">&lt;h1&gt;به نام خدا&lt;/h1&gt;

&lt;p&gt;امروز ایمیلی از طرف پاکت بهم رسید که در اون نوشته شده بود من جزو Top 5% readers پاکت شدم.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://blog.erfan.xyz/stylesheets/images/year-in-pocket-stats.png" alt="Year in Pocket total stats" /&gt;&lt;/p&gt;

&lt;p&gt;به همین مناسبت صفحه‌ای نیز درست کردن که توی این صفحه به طور خلاصه گزارشی از کاربری از این سرویس در سال گذشته نشون داده میشه.&lt;/p&gt;

&lt;p&gt;&lt;a href="http://getpocket.com/stats/fe03daf0177ae04ea6ac629620daab94a5b2000dea6cbe6e852c377e655f3fd1?utm_source=bronto&amp;amp;utm_medium=email&amp;amp;utm_term=See+your+Year+in+Pocket%21&amp;amp;utm_content=%25%25first_name%25%25%2C+you+made+the+Top+1%25+of+readers+on+Pocket+this+year%21&amp;amp;utm_campaign=EOY_2014_1%25_Name&amp;amp;utm_source=bronto&amp;amp;utm_medium=email&amp;amp;utm_term=See+Your+Year+in+Pocket%21&amp;amp;utm_content=%25%25first_name%25%25%2C+you+made+the+Top+5%25+of+readers+on+Pocket+this+year%21&amp;amp;utm_campaign=EOY_2014_5%25_Name"&gt;My 2014 Year in Pocket&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="http://blog.erfan.xyz/stylesheets/images/year-in-pocket-weekly-stat.png" alt="Year in Pocket weekly stats" /&gt;&lt;/p&gt;

&lt;p&gt;امیدوارم در سال بعد، یعنی سال 2015، بیشتر مطالعه داشته باشم، هم با استفاده از این سرویس، هم به طرق دیگه.&lt;/p&gt;
</summary><published>2014-12-16T20:30:00Z</published><updated>2014-12-16T20:30:00Z</updated><link rel="alternate" href="http://blog.erfan.xyz/2014/12/my-year-in-pocket/" /><content type="html">&lt;h1&gt;به نام خدا&lt;/h1&gt;

&lt;p&gt;امروز ایمیلی از طرف پاکت بهم رسید که در اون نوشته شده بود من جزو Top 5% readers پاکت شدم.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://blog.erfan.xyz/stylesheets/images/year-in-pocket-stats.png" alt="Year in Pocket total stats" /&gt;&lt;/p&gt;

&lt;p&gt;به همین مناسبت صفحه‌ای نیز درست کردن که توی این صفحه به طور خلاصه گزارشی از کاربری از این سرویس در سال گذشته نشون داده میشه.&lt;/p&gt;

&lt;p&gt;&lt;a href="http://getpocket.com/stats/fe03daf0177ae04ea6ac629620daab94a5b2000dea6cbe6e852c377e655f3fd1?utm_source=bronto&amp;amp;utm_medium=email&amp;amp;utm_term=See+your+Year+in+Pocket%21&amp;amp;utm_content=%25%25first_name%25%25%2C+you+made+the+Top+1%25+of+readers+on+Pocket+this+year%21&amp;amp;utm_campaign=EOY_2014_1%25_Name&amp;amp;utm_source=bronto&amp;amp;utm_medium=email&amp;amp;utm_term=See+Your+Year+in+Pocket%21&amp;amp;utm_content=%25%25first_name%25%25%2C+you+made+the+Top+5%25+of+readers+on+Pocket+this+year%21&amp;amp;utm_campaign=EOY_2014_5%25_Name"&gt;My 2014 Year in Pocket&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="http://blog.erfan.xyz/stylesheets/images/year-in-pocket-weekly-stat.png" alt="Year in Pocket weekly stats" /&gt;&lt;/p&gt;

&lt;p&gt;امیدوارم در سال بعد، یعنی سال 2015، بیشتر مطالعه داشته باشم، هم با استفاده از این سرویس، هم به طرق دیگه.&lt;/p&gt;
</content></entry><entry><id>http://blog.erfan.xyz/2014/12/1024-vs-1000/</id><title type="text">1024 vs. 1000</title><summary type="html">&lt;h1&gt;به نام خدا&lt;/h1&gt;

&lt;p&gt;راستش رو بخوایید من هم هنوز دقیق نمی‌دونم وقتی به مدل‌های مختلفی می‌نویسن منظور کدومه.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://imgs.xkcd.com/comics/kilobyte.png" alt="1024 vs. 1000" /&gt;&lt;/p&gt;
</summary><published>2014-12-06T20:30:00Z</published><updated>2014-12-06T20:30:00Z</updated><link rel="alternate" href="http://blog.erfan.xyz/2014/12/1024-vs-1000/" /><content type="html">&lt;h1&gt;به نام خدا&lt;/h1&gt;

&lt;p&gt;راستش رو بخوایید من هم هنوز دقیق نمی‌دونم وقتی به مدل‌های مختلفی می‌نویسن منظور کدومه.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://imgs.xkcd.com/comics/kilobyte.png" alt="1024 vs. 1000" /&gt;&lt;/p&gt;
</content></entry></feed>